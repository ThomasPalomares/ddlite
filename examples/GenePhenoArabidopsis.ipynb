{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cPickle, os, sys\n",
    "import random\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "from ddlite import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Processing the input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data extracted from PMC is located in 'DATA_FOLDER' and already structured in json through the code \"ADD NAME PARSING CODE\".\n",
    "We use ddlite's parser to parse the data and dump pickles files of parsed sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Thomas data folder \n",
    "# DATA_FOLDER='/Users/thomaspalomares/Desktop/Stanford/RA/multisentences/data/'\n",
    "#Tanya data folder\n",
    "# DATA_FOLDER='/Users/tanyaberardini/Desktop/DeepDive/data/'\n",
    "DATA_FOLDER='arabidopsis_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # name_file_to_parse='pmc/round2/PMC_round_2'\n",
    "# name_file_to_parse='pmc/round1/output_plant'\n",
    "# # #May have to be modified to conserve correct doc_ids (in particular, write in different txt files)\n",
    "# nb_lines=0\n",
    "# nb_error_parsing=0\n",
    "# with open(DATA_FOLDER+name_file_to_parse+'.json', 'rb') as json_file:\n",
    "#     with open(DATA_FOLDER+name_file_to_parse + '.text', 'wb') as text_write:\n",
    "#         docs={}\n",
    "#         for line in json_file:\n",
    "#             nb_lines+=1\n",
    "#             doc_id_read=str(json.loads(line)['doc-id'].encode('utf-8').strip())\n",
    "# #             try:\n",
    "#             #Because this doc is too big\n",
    "#             if doc_id_read=='10.1093.jxb.eru198':\n",
    "#                 if random.random() <0.5:\n",
    "#                     doc_id_read += '_1'\n",
    "#                 else:\n",
    "#                     doc_id_read += '_2'\n",
    "#             if doc_id_read in docs:\n",
    "#                 docs[doc_id_read] += unicode(str(json.loads(line)['content'].encode('utf-8').strip()) + '.\\n', errors='ignore')\n",
    "#             else:\n",
    "#                 docs[doc_id_read] = unicode(str(json.loads(line)['content'].encode('utf-8').strip()) + '.\\n', errors='ignore')\n",
    "# #                 text_write.write(unicode(str(json.loads(line)['content'].encode('utf-8').strip()) + '.\\n', errors='ignore'))\n",
    "# #             except:\n",
    "# #                 nb_error_parsing +=1\n",
    "# #                 print \"error parsing\"\n",
    "# print nb_lines\n",
    "# print nb_error_parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # pkl_f=DATA_FOLDER+'pmc/pickle/pkl_sentences_round_2'\n",
    "# pkl_f=DATA_FOLDER+'pmc/pickle/pkl_sentences'\n",
    "# sents=[]\n",
    "# count_loop=0\n",
    "# parser_sent = SentenceParser()\n",
    "# try:\n",
    "#     with open(pkl_f, 'rb') as f:\n",
    "#         sents = cPickle.load(f)\n",
    "# except:\n",
    "#     print\"parsing data\"\n",
    "#     for doc_id_loop in docs:\n",
    "#         count_loop+=1\n",
    "#         print count_loop\n",
    "#         for j in parser_sent.parse(docs[doc_id_loop], doc_id=doc_id_loop):\n",
    "#             sents.append(j)\n",
    "#     with open(pkl_f, 'w+') as f:\n",
    "#         cPickle.dump(sents, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Brief code to merge round1 and round2 data.\n",
    "#Not great currently, to be improved with try and except.\n",
    "\n",
    "with open(DATA_FOLDER+'pmc/pickle/pkl_sentences', 'rb') as f:\n",
    "    sents1=cPickle.load(f)\n",
    "    \n",
    "with open(DATA_FOLDER+'pmc/pickle/pkl_sentences_round_2', 'rb') as f:\n",
    "    sents2=cPickle.load(f)\n",
    "\n",
    "sents = sents1 + sents2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62655\n",
      "Sentence(words=[u'PROTEIN', u'TARGETING', u'TO', u'STARCH', u'Is', u'Required', u'for', u'Localising', u'GRANULE-BOUND', u'STARCH', u'SYNTHASE', u'to', u'Starch', u'Granules', u'and', u'for', u'Normal', u'Amylose', u'Synthesis', u'in', u'Arabidopsis', u'.'], lemmas=[u'PROTEIN', u'TARGETING', u'to', u'STARCH', u'be', u'require', u'for', u'localise', u'granule-bound', u'starch', u'synthase', u'to', u'Starch', u'Granules', u'and', u'for', u'normal', u'Amylose', u'synthesis', u'in', u'Arabidopsis', u'.'], poses=[u'NNP', u'NNP', u'TO', u'NNP', u'VBZ', u'VBN', u'IN', u'VBG', u'JJ', u'NN', u'NN', u'TO', u'NNP', u'NNPS', u'CC', u'IN', u'JJ', u'NNP', u'NN', u'IN', u'NNP', u'.'], dep_parents=[2, 6, 4, 2, 6, 0, 11, 11, 11, 11, 6, 14, 14, 11, 6, 19, 19, 19, 6, 21, 19, 6], dep_labels=[u'compound', u'nsubjpass', u'case', u'nmod', u'auxpass', u'ROOT', u'case', u'amod', u'amod', u'compound', u'nmod', u'case', u'compound', u'nmod', u'cc', u'case', u'amod', u'compound', u'conj', u'case', u'nmod', u'punct'], sent_id=0, doc_id='PBIOLOGY-D-14-02490', text=u'PROTEIN TARGETING TO STARCH Is Required for Localising GRANULE-BOUND STARCH SYNTHASE to Starch Granules and for Normal Amylose Synthesis in Arabidopsis.', token_idxs=[0, 8, 18, 21, 28, 31, 40, 44, 55, 69, 76, 85, 88, 95, 104, 108, 112, 119, 127, 137, 140, 151], doc_name=None)\n"
     ]
    }
   ],
   "source": [
    "print len(sents)\n",
    "print sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sents_tot = sents1 + sents2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "Sentence(words=[u'PROTEIN', u'TARGETING', u'TO', u'STARCH', u'Is', u'Required', u'for', u'Localising', u'GRANULE-BOUND', u'STARCH', u'SYNTHASE', u'to', u'Starch', u'Granules', u'and', u'for', u'Normal', u'Amylose', u'Synthesis', u'in', u'Arabidopsis', u'.'], lemmas=[u'PROTEIN', u'TARGETING', u'to', u'STARCH', u'be', u'require', u'for', u'localise', u'granule-bound', u'starch', u'synthase', u'to', u'Starch', u'Granules', u'and', u'for', u'normal', u'Amylose', u'synthesis', u'in', u'Arabidopsis', u'.'], poses=[u'NNP', u'NNP', u'TO', u'NNP', u'VBZ', u'VBN', u'IN', u'VBG', u'JJ', u'NN', u'NN', u'TO', u'NNP', u'NNPS', u'CC', u'IN', u'JJ', u'NNP', u'NN', u'IN', u'NNP', u'.'], dep_parents=[2, 6, 4, 2, 6, 0, 11, 11, 11, 11, 6, 14, 14, 11, 6, 19, 19, 19, 6, 21, 19, 6], dep_labels=[u'compound', u'nsubjpass', u'case', u'nmod', u'auxpass', u'ROOT', u'case', u'amod', u'amod', u'compound', u'nmod', u'case', u'compound', u'nmod', u'cc', u'case', u'amod', u'compound', u'conj', u'case', u'nmod', u'punct'], sent_id=0, doc_id='PBIOLOGY-D-14-02490', text=u'PROTEIN TARGETING TO STARCH Is Required for Localising GRANULE-BOUND STARCH SYNTHASE to Starch Granules and for Normal Amylose Synthesis in Arabidopsis.', token_idxs=[0, 8, 18, 21, 28, 31, 40, 44, 55, 69, 76, 85, 88, 95, 104, 108, 112, 119, 127, 137, 140, 151], doc_name=None)\n"
     ]
    }
   ],
   "source": [
    "# ###BRIEF TEST TO BE REMOVED\n",
    "sents=sents_tot[0:1000]\n",
    "# sents=sents_tot\n",
    "print len(sents)\n",
    "print sents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidate mention Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting candidates for relations in ddlite is done with Matcher objects. We first extract all the mentions of Genes and Phenotypes in the sentences. The dictionaries are located in the 'dicts' folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the gene extraction, we use a dictionary of genes on which we remove some blacklist words.\n",
    "We then need to extend it for alleles and multiple mutant. For that, an "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genes=[]\n",
    "for row_genes in [line.rstrip().split('\\t') for line in open(DATA_FOLDER + '/dicts/list_genes.txt')]:\n",
    "    for gene in row_genes:\n",
    "        genes.append(gene)\n",
    "        \n",
    "#Removing blacklist_words\n",
    "blacklist_words = [line.rstrip().split('\\t')[1].lower() for line in open(DATA_FOLDER + '/dicts/blacklist_words.txt')][1:]\n",
    "genes_filtered = [x.lower() for x in genes if x.lower() not in blacklist_words]\n",
    "\n",
    "#Do using concat function from candidate_extractor_2 branch with a regex\n",
    "#Adding alleles possibilities (only the longest match is kept anyway)\n",
    "genes_with_alleles_1 = [\"_ \" + x + \" _ - \" + str(i) for x in genes_filtered for i in range(10)]\n",
    "genes_with_alleles_1_bis = [\"_ \" + x + \" _ -\" + str(i) for x in genes_filtered for i in range(10)]\n",
    "genes_with_alleles_2 = [\"_ \" + x + \" _ - _ \" + str(i) + \" _\" for x in genes_filtered for i in range(10)]\n",
    "genes_with_alleles_3 = [x + \" - \" + str(i) for x in genes_filtered for i in range(10)]\n",
    "\n",
    "\n",
    "\n",
    "genes_tot= genes_filtered + genes_with_alleles_1+ genes_with_alleles_1_bis + genes_with_alleles_2 + genes_with_alleles_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gene_dm = DictionaryMatch(label='GeneName', dictionary=genes_filtered, ignore_case=False)\n",
    "gene_dm = ConcatDictionaryMatch(label='GeneName', dictionary=genes_tot, ignore_case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary match should provide fairly high recall, but we may still miss some candidates. We know that gene names are named nouns and are often all uppercase. Let's use DDLite's compositional matcher operations to handle this. First, we'll write a matcher to find all nouns using the parts-of-speech tags. Then, we'll use a filter to find uppercase sequences. Finally, we'll use a filter to make sure each match has at least 3 characters. We pass noun_rm to up_rm, and up_rm to the final filter to compose them with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noun_regex = RegexNgramMatch(label='Nouns', regex_pattern=r'[A-Z]?NN[A-Z]?', ignore_case=True, match_attrib='poses')\n",
    "up_regex = RegexFilterAll(noun_regex, label='Upper', regex_pattern=r'[A-Z]+([0-9]+)?([A-Z]+)?([0-9]+)?$', ignore_case=False, match_attrib='words')\n",
    "multi_regex = RegexFilterAll(up_regex, label='Multi', regex_pattern=r'[a-z0-9]{3,}', ignore_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want matches both from the dictionary and the uppercase-noun-phrase-matcher we just built, we'll use the union object to create a matcher for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The previous regexes seem to catch many patterns not wanted (like 'and' or others), let's ignore it for now and we can add it when we'll work on recall\n",
    "# GM = Union(gene_dm, multi_regex)\n",
    "GM=gene_dm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pheno extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Schema is: HPO_ID | NAME | TYPE (exact, lemma)\n",
    "phenos_deepdive = [line.rstrip().split('\\t')[1] for line in open(DATA_FOLDER + '/dicts/pheno_terms.tsv')]\n",
    "phenos_arabidopsis = [line.rstrip() for line in open(DATA_FOLDER + '/dicts/list_phenotypes_arabidopsis_filtered.txt')]\n",
    "phenos_worm_variants = [line.rstrip() for line in open(DATA_FOLDER + '/dicts/worm_variants_unix.txt')]\n",
    "phenos_all_eq_dict = [pheno.strip() for line in open(DATA_FOLDER + 'dicts/phenotypes_all_eq_dict.txt') for pheno in line.rstrip().split(';')]\n",
    "phenos_manual = [line.rstrip() for line in open(DATA_FOLDER + '/dicts/phenotypes_manual.txt')]\n",
    "\n",
    "phenos_tot_dicts = phenos_deepdive + phenos_arabidopsis + phenos_worm_variants + phenos_all_eq_dict + phenos_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to read obo files (from the obo foundry, for PATO, CHEBI and PO)\n",
    "\"\"\"\n",
    "A constant-space parser for the GeneOntology OBO v1.2 format\n",
    "\n",
    "Version 1.0\n",
    "\"\"\"\n",
    "from __future__ import with_statement\n",
    "from collections import defaultdict\n",
    "\n",
    "__author__    = \"Uli Koehler\"\n",
    "__copyright__ = \"Copyright 2013 Uli Koehler\"\n",
    "__license__   = \"Apache v2.0\"\n",
    "\n",
    "def processGOTerm(goTerm):\n",
    "    \"\"\"\n",
    "    In an object representing a GO term, replace single-element lists with\n",
    "    their only member.\n",
    "    Returns the modified object as a dictionary.\n",
    "    \"\"\"\n",
    "    ret = dict(goTerm) #Input is a defaultdict, might express unexpected behaviour\n",
    "    for key, value in ret.iteritems():\n",
    "        if len(value) == 1:\n",
    "            ret[key] = value[0]\n",
    "    return ret\n",
    "\n",
    "def parseGOOBO(filename):\n",
    "    \"\"\"\n",
    "    Parses a Gene Ontology dump in OBO v1.2 format.\n",
    "    Yields each \n",
    "    Keyword arguments:\n",
    "        filename: The filename to read\n",
    "    \"\"\"\n",
    "    with open(filename, \"r\") as infile:\n",
    "        currentGOTerm = None\n",
    "        for line in infile:\n",
    "            line = line.strip()\n",
    "            if not line: continue #Skip empty\n",
    "            if line == \"[Term]\":\n",
    "                if currentGOTerm: yield processGOTerm(currentGOTerm)\n",
    "                currentGOTerm = defaultdict(list)\n",
    "            elif line == \"[Typedef]\":\n",
    "                #Skip [Typedef sections]\n",
    "                currentGOTerm = None\n",
    "            else: #Not [Term]\n",
    "                #Only process if we're inside a [Term] environment\n",
    "                if currentGOTerm is None: continue\n",
    "                key, sep, val = line.partition(\":\")\n",
    "                currentGOTerm[key].append(val.strip())\n",
    "        #Add last term\n",
    "        if currentGOTerm is not None:\n",
    "            yield processGOTerm(currentGOTerm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "po_ontology = []\n",
    "test_count=0\n",
    "for elt in parseGOOBO(DATA_FOLDER + 'dicts/po.obo'):\n",
    "    test_count+=1\n",
    "    po_ontology.append(elt['name'])\n",
    "    if 'synonym' in elt:\n",
    "        if isinstance(elt['synonym'], list):\n",
    "            for syn in elt['synonym']:\n",
    "                try:\n",
    "                    po_ontology.append(syn.split('\"')[1])\n",
    "                except:\n",
    "                    print 'error'\n",
    "        else:\n",
    "            try:\n",
    "                po_ontology.append(elt['synonym'].split('\"')[1])\n",
    "            except:\n",
    "                print 'error non list'\n",
    "\n",
    "\n",
    "chebi_ontology =[]\n",
    "for elt in parseGOOBO(DATA_FOLDER + 'dicts/chebi.obo'):\n",
    "    chebi_ontology.append(elt['name'])\n",
    "    if 'synonym' in elt:\n",
    "        if isinstance(elt['synonym'], list):\n",
    "            for syn in elt['synonym']:\n",
    "                try:\n",
    "                    chebi_ontology.append(syn.split('\"')[1])\n",
    "                except:\n",
    "                    print 'error'\n",
    "        else:\n",
    "            try:\n",
    "                chebi_ontology.append(elt['synonym'].split('\"')[1])\n",
    "            except:\n",
    "                print 'error non list'\n",
    "    \n",
    "pato_ontology =[]\n",
    "for elt in parseGOOBO(DATA_FOLDER + 'dicts/pato.obo'):\n",
    "    pato_ontology.append(elt['name'])\n",
    "    if 'synonym' in elt:\n",
    "        if isinstance(elt['synonym'], list):\n",
    "            for syn in elt['synonym']:\n",
    "                try:\n",
    "                    pato_ontology.append(syn.split('\"')[1])\n",
    "                except:\n",
    "                    print 'error'\n",
    "        else:\n",
    "            try:\n",
    "                pato_ontology.append(elt['synonym'].split('\"')[1])\n",
    "            except:\n",
    "                print 'error non list'\n",
    "                \n",
    "go_ontology =[]\n",
    "for elt in parseGOOBO(DATA_FOLDER + 'dicts/go-basic.obo'):\n",
    "    go_ontology.append(elt['name'])\n",
    "    if 'synonym' in elt:\n",
    "        if isinstance(elt['synonym'], list):\n",
    "            for syn in elt['synonym']:\n",
    "                try:\n",
    "                    go_ontology.append(syn.split('\"')[1])\n",
    "                except:\n",
    "                    print 'error'\n",
    "        else:\n",
    "            try:\n",
    "                go_ontology.append(elt['synonym'].split('\"')[1])\n",
    "            except:\n",
    "                print 'error non list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dictionnary of linkwords to be added to the 'quality' dictionnary for the phenotype extraction.\n",
    "#Very small currently, need to be extended.\n",
    "dict_linkwords = ['of', 'over', 'in', 'the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# phenos_tot = phenos_tot_dicts + po_ontology + chebi_ontology + pato_ontology\n",
    "phenos_tot = phenos_tot_dicts + po_ontology + chebi_ontology + go_ontology\n",
    "quality_dict = pato_ontology + dict_linkwords\n",
    "\n",
    "#Removing the phenotypes that are in the blacklist.\n",
    "blacklist_words = [line.rstrip().split('\\t')[1].lower() for line in open(DATA_FOLDER + '/dicts/blacklist_words.txt')][1:]\n",
    "phenos_tot_filtered = [x.lower() for x in phenos_tot if x.lower() not in blacklist_words]\n",
    "\n",
    "PM = ConcatDictionaryMatch(label='PhenoName', dictionary=phenos_tot_filtered, dictionary_optional=quality_dict, ignore_case=True, match_attrib='lemmas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence, we extract a candidate relation for each pair (gene, phenotype) appearing in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R = Relations(sents, GM, PM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".node {\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".node circle {\n",
       "  fill: #fff;\n",
       "  stroke: steelblue;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "\n",
       ".node text {\n",
       "  font: 12px sans-serif;\n",
       "}\n",
       "\n",
       ".edge {\n",
       "  fill: none;\n",
       "  stroke: #ccc;\n",
       "  stroke-width: 2px;\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".highlight {\n",
       "  stroke: red;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<!--Provide the canvas id (twice) and the words via python string formatting here--!>\n",
       "<div id=\"tree-chart-8752789955413998394\"></div>\n",
       "<div id=\"raw-seq-8752789955413998394\">\n",
       "<span class=\"word-8752789955413998394-0\">The</span> <span class=\"word-8752789955413998394-1\">_</span> <span class=\"word-8752789955413998394-2\">ptst</span> <span class=\"word-8752789955413998394-3\">_</span> <span class=\"word-8752789955413998394-4\">-</span> <span class=\"word-8752789955413998394-5\">_</span> <span class=\"word-8752789955413998394-6\">1</span> <span class=\"word-8752789955413998394-7\">_</span> <span class=\"word-8752789955413998394-8\">mutant</span> <span class=\"word-8752789955413998394-9\">is</span> <span class=\"word-8752789955413998394-10\">in</span> <span class=\"word-8752789955413998394-11\">the</span> <span class=\"word-8752789955413998394-12\">Columbia</span> <span class=\"word-8752789955413998394-13\">(</span> <span class=\"word-8752789955413998394-14\">Col</span> <span class=\"word-8752789955413998394-15\">)</span> <span class=\"word-8752789955413998394-16\">ecotype</span> <span class=\"word-8752789955413998394-17\">background</span> <span class=\"word-8752789955413998394-18\">while</span> <span class=\"word-8752789955413998394-19\">_</span> <span class=\"word-8752789955413998394-20\">ptst-2</span> <span class=\"word-8752789955413998394-21\">_</span> <span class=\"word-8752789955413998394-22\">is</span> <span class=\"word-8752789955413998394-23\">in</span> <span class=\"word-8752789955413998394-24\">the</span> <span class=\"word-8752789955413998394-25\">Wassilewskija</span> <span class=\"word-8752789955413998394-26\">(</span> <span class=\"word-8752789955413998394-27\">Ws</span> <span class=\"word-8752789955413998394-28\">)</span> <span class=\"word-8752789955413998394-29\">background</span> <span class=\"word-8752789955413998394-30\">.</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "$.getScript(\"http://d3js.org/d3.v3.min.js\", function () {\n",
       "// See http://bl.ocks.org/d3noob/8375092\n",
       "// Three vars need to be provided via python string formatting:\n",
       "var chartId = \"8752789955413998394\";\n",
       "var root = {\"attrib\": {\"token_idx\": \"11510\", \"word\": \"mutant\", \"dep_label\": \"ROOT\", \"pos\": \"NN\", \"lemma\": \"mutant\", \"word_idx\": \"8\", \"dep_parent\": \"0\"}, \"children\": [{\"attrib\": {\"token_idx\": \"11500\", \"word\": \"ptst\", \"dep_label\": \"nsubj\", \"pos\": \"NN\", \"lemma\": \"ptst\", \"word_idx\": \"2\", \"dep_parent\": \"9\"}, \"children\": [{\"attrib\": {\"token_idx\": \"11495\", \"word\": \"The\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"the\", \"word_idx\": \"0\", \"dep_parent\": \"3\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"11499\", \"word\": \"_\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"_\", \"word_idx\": \"1\", \"dep_parent\": \"3\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"11504\", \"word\": \"_\", \"dep_label\": \"amod\", \"pos\": \"SYM\", \"lemma\": \"_\", \"word_idx\": \"3\", \"dep_parent\": \"9\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"11505\", \"word\": \"-\", \"dep_label\": \"punct\", \"pos\": \":\", \"lemma\": \"-\", \"word_idx\": \"4\", \"dep_parent\": \"9\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"11506\", \"word\": \"_\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"_\", \"word_idx\": \"5\", \"dep_parent\": \"9\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"11507\", \"word\": \"1\", \"dep_label\": \"nummod\", \"pos\": \"CD\", \"lemma\": \"1\", \"word_idx\": \"6\", \"dep_parent\": \"9\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"11508\", \"word\": \"_\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"_\", \"word_idx\": \"7\", \"dep_parent\": \"9\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"11550\", \"word\": \"background\", \"dep_label\": \"dep\", \"pos\": \"NN\", \"lemma\": \"background\", \"word_idx\": \"17\", \"dep_parent\": \"9\"}, \"children\": [{\"attrib\": {\"token_idx\": \"11517\", \"word\": \"is\", \"dep_label\": \"cop\", \"pos\": \"VBZ\", \"lemma\": \"be\", \"word_idx\": \"9\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"11520\", \"word\": \"in\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"in\", \"word_idx\": \"10\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"11523\", \"word\": \"the\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"the\", \"word_idx\": \"11\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"11527\", \"word\": \"Columbia\", \"dep_label\": \"compound\", \"pos\": \"NNP\", \"lemma\": \"Columbia\", \"word_idx\": \"12\", \"dep_parent\": \"18\"}, \"children\": [{\"attrib\": {\"token_idx\": \"11537\", \"word\": \"Col\", \"dep_label\": \"appos\", \"pos\": \"NNP\", \"lemma\": \"Col\", \"word_idx\": \"14\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"token_idx\": \"11536\", \"word\": \"-LRB-\", \"dep_label\": \"punct\", \"pos\": \"-LRB-\", \"lemma\": \"-lrb-\", \"word_idx\": \"13\", \"dep_parent\": \"15\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"11540\", \"word\": \"-RRB-\", \"dep_label\": \"punct\", \"pos\": \"-RRB-\", \"lemma\": \"-rrb-\", \"word_idx\": \"15\", \"dep_parent\": \"15\"}, \"children\": []}]}]}, {\"attrib\": {\"token_idx\": \"11542\", \"word\": \"ecotype\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"ecotype\", \"word_idx\": \"16\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"11605\", \"word\": \"background\", \"dep_label\": \"advcl\", \"pos\": \"NN\", \"lemma\": \"background\", \"word_idx\": \"29\", \"dep_parent\": \"18\"}, \"children\": [{\"attrib\": {\"token_idx\": \"11561\", \"word\": \"while\", \"dep_label\": \"mark\", \"pos\": \"IN\", \"lemma\": \"while\", \"word_idx\": \"18\", \"dep_parent\": \"30\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"11574\", \"word\": \"_\", \"dep_label\": \"nsubj\", \"pos\": \"NN\", \"lemma\": \"_\", \"word_idx\": \"21\", \"dep_parent\": \"30\"}, \"children\": [{\"attrib\": {\"token_idx\": \"11567\", \"word\": \"_\", \"dep_label\": \"nummod\", \"pos\": \"CD\", \"lemma\": \"_\", \"word_idx\": \"19\", \"dep_parent\": \"22\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"11568\", \"word\": \"ptst-2\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"ptst-2\", \"word_idx\": \"20\", \"dep_parent\": \"22\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"11576\", \"word\": \"is\", \"dep_label\": \"cop\", \"pos\": \"VBZ\", \"lemma\": \"be\", \"word_idx\": \"22\", \"dep_parent\": \"30\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"11579\", \"word\": \"in\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"in\", \"word_idx\": \"23\", \"dep_parent\": \"30\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"11582\", \"word\": \"the\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"the\", \"word_idx\": \"24\", \"dep_parent\": \"30\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"11586\", \"word\": \"Wassilewskija\", \"dep_label\": \"compound\", \"pos\": \"NNP\", \"lemma\": \"Wassilewskija\", \"word_idx\": \"25\", \"dep_parent\": \"30\"}, \"children\": [{\"attrib\": {\"token_idx\": \"11601\", \"word\": \"Ws\", \"dep_label\": \"appos\", \"pos\": \"NNS\", \"lemma\": \"w\", \"word_idx\": \"27\", \"dep_parent\": \"26\"}, \"children\": [{\"attrib\": {\"token_idx\": \"11600\", \"word\": \"-LRB-\", \"dep_label\": \"punct\", \"pos\": \"-LRB-\", \"lemma\": \"-lrb-\", \"word_idx\": \"26\", \"dep_parent\": \"28\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"11603\", \"word\": \"-RRB-\", \"dep_label\": \"punct\", \"pos\": \"-RRB-\", \"lemma\": \"-rrb-\", \"word_idx\": \"28\", \"dep_parent\": \"28\"}, \"children\": []}]}]}]}]}, {\"attrib\": {\"token_idx\": \"11615\", \"word\": \".\", \"dep_label\": \"punct\", \"pos\": \".\", \"lemma\": \".\", \"word_idx\": \"30\", \"dep_parent\": \"9\"}, \"children\": []}]};\n",
       "var highlightIdxs = [[1, 2, 3, 4, 5, 6, 7], [27]];\n",
       "\n",
       "// Highlight words / nodes\n",
       "var COLORS = [\"#ff5c33\", \"#ffcc00\", \"#33cc33\", \"#3399ff\"];\n",
       "function highlightWords() {\n",
       "  for (var i=0; i < highlightIdxs.length; i++) {\n",
       "    var c = COLORS[i];\n",
       "    var idxs = highlightIdxs[i];\n",
       "    for (var j=0; j < idxs.length; j++) {\n",
       "      d3.selectAll(\".word-\"+chartId+\"-\"+idxs[j]).style(\"stroke\", c).style(\"background\", c);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "// Constants\n",
       "var margin = {top: 20, right: 20, bottom: 20, left: 20},\n",
       "width = 800 - margin.left - margin.right,\n",
       "height = 350 - margin.top - margin.bottom,\n",
       "R = 5;\n",
       "\n",
       "// Create the d3 tree object\n",
       "var tree = d3.layout.tree()\n",
       "  .size([width, height]);\n",
       "\n",
       "// Create the svg canvas\n",
       "var svg = d3.select(\"#tree-chart-\" + chartId)\n",
       "  .append(\"svg\")\n",
       "  .attr(\"width\", width + margin.left + margin.right)\n",
       "  .attr(\"height\", height + margin.top + margin.bottom)\n",
       "  .append(\"g\")\n",
       "  .attr(\"transform\", \"translate(\" + margin.left + \",\" + margin.top + \")\");\n",
       "\n",
       "function renderTree() {\n",
       "  var nodes = tree.nodes(root),\n",
       "  edges = tree.links(nodes);\n",
       "\n",
       "  // Place the nodes\n",
       "  var nodeGroups = svg.selectAll(\"g.node\")\n",
       "    .data(nodes)\n",
       "    .enter().append(\"g\")\n",
       "    .attr(\"class\", \"node\")\n",
       "    .attr(\"transform\", function(d) { return \"translate(\" + d.x + \",\" + d.y + \")\"; });\n",
       "       \n",
       "  // Append circles\n",
       "  nodeGroups.append(\"circle\")\n",
       "    //.on(\"click\", function() {\n",
       "    //  d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"r\", R)\n",
       "    .attr(\"class\", function(d) { return \"word-\"+chartId+\"-\"+d.attrib.word_idx; });\n",
       "     \n",
       "  // Append the actual word\n",
       "  nodeGroups.append(\"text\")\n",
       "    .text(function(d) { return d.attrib.word; })\n",
       "    .attr(\"text-anchor\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? \"start\" : \"middle\"; })\n",
       "    .attr(\"dx\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? R + 3 : 0; })\n",
       "    .attr(\"dy\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? 0 : 3*R + 3; });\n",
       "\n",
       "  // Place the edges\n",
       "  var edgePaths = svg.selectAll(\"path\")\n",
       "    .data(edges)\n",
       "    .enter().append(\"path\")\n",
       "    .attr(\"class\", \"edge\")\n",
       "    .on(\"click\", function() {\n",
       "      d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"d\", d3.svg.diagonal());\n",
       "}\n",
       "\n",
       "renderTree();\n",
       "highlightWords();\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "R[5].render()\n",
    "# R[5].poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_sent=9\n",
    "# for i in range(len(R[test_sent].dep_parents)):\n",
    "#     print i, R[test_sent].words[i], R[test_sent].dep_parents[i], R[test_sent].poses[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# R.dump_candidates('pickle/relations.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ddlite Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a ddlite model from the previous candidates, on which we will extract features, define labeling functions and learn a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 11062 features for each of 425 relations\n"
     ]
    }
   ],
   "source": [
    "DDL = DDLiteModel(R)\n",
    "print \"Extracted {} features for each of {} relations\".format(DDL.num_feats(), DDL.num_candidates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a gold ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We label here a certain amount of sentences that will allow us to evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Importing previous mentions labeled\n",
    "tags_files = [DATA_FOLDER + 'tags/' + name_tag for name_tag in ['tags_fccb81915ae086e3', 'tags_May_24.tsv']] \n",
    "tags_list=[]\n",
    "for tags_file in tags_files:\n",
    "    first_line=True\n",
    "    with open(tags_file, 'rb') as f:\n",
    "        for line in f:\n",
    "            if first_line:\n",
    "                header=line.rstrip().split('\\t')\n",
    "                first_line=False\n",
    "            else:\n",
    "                res={}\n",
    "                for i, item in enumerate(line.rstrip().split('\\t')):\n",
    "                    res[header[i]]=item\n",
    "                res['sent_id']=int(res['sent_id'])\n",
    "                res['e1_idxs'] = map(int, res['e1_idxs'][1:-1].split(','))\n",
    "                res['e2_idxs'] = map(int, res['e2_idxs'][1:-1].split(','))\n",
    "                tags_list.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "{'e2_idxs': [7], 'wrong gene': '\\\\N', 'e1_label': 'GeneName', 'probability': '', 'e2_label': 'PhenoName', 'sent_id': 132, 'multiple mutant': '\\\\N', 'is_correct': 'false', 'one word phenotype not useful': '\\\\N', 'words': '[\"However\", \",\", \"the\", \"rates\", \"of\", \"germination\", \"and\", \"cotyledon\", \"greening\", \"among\", \"_\", \"abi4\", \"_\", \",\", \"WT\", \"and\", \"_\", \"OE-ABI4\", \"_\", \"were\", \"comparable\", \"when\", \"we\", \"used\", \"medium\", \"supplemented\", \"with\", \"exogenous\", \"GA.\", \".\"]', 'wrong phenotype': 'true', 'e1_idxs': [11], 'doc_id': '10.1371.journal.pgen.1003577', 'overlapping gene and phenotype': '\\\\N', 'ext_id': '430'}\n"
     ]
    }
   ],
   "source": [
    "print len(tags_list)\n",
    "print tags_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Finding the index in DDL of our labeled data\n",
    "def func_DDL_index_with_tag(DDL_var, tag_var):\n",
    "#     count=0\n",
    "    for i in range(DDL.num_candidates()):\n",
    "        if DDL.C[i].doc_id==tag_var['doc_id']:\n",
    "            if DDL.C[i].sent_id==tag_var['sent_id']:\n",
    "                if DDL.C[i].e1_idxs==tag_var['e1_idxs']:\n",
    "                    if DDL.C[i].e2_idxs==tag_var['e2_idxs']:\n",
    "#                         count+=1\n",
    "                        return DDL.C[i].uid\n",
    "    return -1\n",
    "#     if count >1:\n",
    "#         print 'WEIRD: more than one element found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../ddlite.py:600: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  self.dev1 = idxs[ : np.floor(dev_split * len(idxs))]\n",
      "../ddlite.py:601: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  self.dev2 = idxs[np.floor(dev_split * len(idxs)) : ]\n",
      "../ddlite.py:592: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  self.validation = h[ : np.floor(validation_frac * len(h))]\n",
      "../ddlite.py:593: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  self.test = h[np.floor(validation_frac * len(h)) : ]\n"
     ]
    }
   ],
   "source": [
    "#Creating the corresponding gold file\n",
    "gold =[]\n",
    "gold_uids = []\n",
    "for i in range(len(tags_list)):\n",
    "    uid_idx = func_DDL_index_with_tag(DDL, tags_list[i])\n",
    "    if uid_idx > -1:\n",
    "        if tags_list[i]['is_correct']=='false':\n",
    "            gold.append(-1)\n",
    "            gold_uids.append(uid_idx)\n",
    "        if tags_list[i]['is_correct']=='true':\n",
    "            gold.append(1)\n",
    "            gold_uids.append(uid_idx)\n",
    "            \n",
    "DDL.update_gt(gold, uids=gold_uids)\n",
    "DDL.set_holdout(validation_frac=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print len(gold)\n",
    "print gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making sure MindTagger is installed. Hang on!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"1200\"\n",
       "            src=\"http://Thomass-MacBook-Pro-99.local:8971/#/mindtagger/4575ec10131a7453\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x18f9771d0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Yellow: gene. Blue: phenotype\n",
    "DDL.open_mindtagger(num_sample=200, width='100%', height=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DDL.add_mindtagger_tags()\n",
    "# DDL.get_ground_truth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16] [31, 32, 33, 34, 35] At the fully developed ovule stage the _ spl/nzz _ mutant phenotype resembles that of _ ashh2 _ , but in contrast to _ ashh2 , spl/nzz _ is characterized by the absence of a MMC at an early stage of ovule development , thus preventing embryo sac formation .\n",
      "At the fully developed ovule stage the _ spl/nzz _ mutant phenotype resembles that of _ {{GeneName}} _ , but in contrast to _ ashh2 , spl/nzz _ is characterized by {{PhenoName}} at an early stage of ovule development , thus preventing embryo sac formation .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".node {\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".node circle {\n",
       "  fill: #fff;\n",
       "  stroke: steelblue;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "\n",
       ".node text {\n",
       "  font: 12px sans-serif;\n",
       "}\n",
       "\n",
       ".edge {\n",
       "  fill: none;\n",
       "  stroke: #ccc;\n",
       "  stroke-width: 2px;\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".highlight {\n",
       "  stroke: red;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<!--Provide the canvas id (twice) and the words via python string formatting here--!>\n",
       "<div id=\"tree-chart-5982185982202176091\"></div>\n",
       "<div id=\"raw-seq-5982185982202176091\">\n",
       "<span class=\"word-5982185982202176091-0\">At</span> <span class=\"word-5982185982202176091-1\">the</span> <span class=\"word-5982185982202176091-2\">fully</span> <span class=\"word-5982185982202176091-3\">developed</span> <span class=\"word-5982185982202176091-4\">ovule</span> <span class=\"word-5982185982202176091-5\">stage</span> <span class=\"word-5982185982202176091-6\">the</span> <span class=\"word-5982185982202176091-7\">_</span> <span class=\"word-5982185982202176091-8\">spl/nzz</span> <span class=\"word-5982185982202176091-9\">_</span> <span class=\"word-5982185982202176091-10\">mutant</span> <span class=\"word-5982185982202176091-11\">phenotype</span> <span class=\"word-5982185982202176091-12\">resembles</span> <span class=\"word-5982185982202176091-13\">that</span> <span class=\"word-5982185982202176091-14\">of</span> <span class=\"word-5982185982202176091-15\">_</span> <span class=\"word-5982185982202176091-16\">ashh2</span> <span class=\"word-5982185982202176091-17\">_</span> <span class=\"word-5982185982202176091-18\">,</span> <span class=\"word-5982185982202176091-19\">but</span> <span class=\"word-5982185982202176091-20\">in</span> <span class=\"word-5982185982202176091-21\">contrast</span> <span class=\"word-5982185982202176091-22\">to</span> <span class=\"word-5982185982202176091-23\">_</span> <span class=\"word-5982185982202176091-24\">ashh2</span> <span class=\"word-5982185982202176091-25\">,</span> <span class=\"word-5982185982202176091-26\">spl/nzz</span> <span class=\"word-5982185982202176091-27\">_</span> <span class=\"word-5982185982202176091-28\">is</span> <span class=\"word-5982185982202176091-29\">characterized</span> <span class=\"word-5982185982202176091-30\">by</span> <span class=\"word-5982185982202176091-31\">the</span> <span class=\"word-5982185982202176091-32\">absence</span> <span class=\"word-5982185982202176091-33\">of</span> <span class=\"word-5982185982202176091-34\">a</span> <span class=\"word-5982185982202176091-35\">MMC</span> <span class=\"word-5982185982202176091-36\">at</span> <span class=\"word-5982185982202176091-37\">an</span> <span class=\"word-5982185982202176091-38\">early</span> <span class=\"word-5982185982202176091-39\">stage</span> <span class=\"word-5982185982202176091-40\">of</span> <span class=\"word-5982185982202176091-41\">ovule</span> <span class=\"word-5982185982202176091-42\">development</span> <span class=\"word-5982185982202176091-43\">,</span> <span class=\"word-5982185982202176091-44\">thus</span> <span class=\"word-5982185982202176091-45\">preventing</span> <span class=\"word-5982185982202176091-46\">embryo</span> <span class=\"word-5982185982202176091-47\">sac</span> <span class=\"word-5982185982202176091-48\">formation</span> <span class=\"word-5982185982202176091-49\">.</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "$.getScript(\"http://d3js.org/d3.v3.min.js\", function () {\n",
       "// See http://bl.ocks.org/d3noob/8375092\n",
       "// Three vars need to be provided via python string formatting:\n",
       "var chartId = \"5982185982202176091\";\n",
       "var root = {\"attrib\": {\"token_idx\": \"27317\", \"word\": \"resembles\", \"dep_label\": \"ROOT\", \"pos\": \"VBZ\", \"lemma\": \"resemble\", \"word_idx\": \"12\", \"dep_parent\": \"0\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27280\", \"word\": \"stage\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"stage\", \"word_idx\": \"5\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27251\", \"word\": \"At\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"at\", \"word_idx\": \"0\", \"dep_parent\": \"6\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27254\", \"word\": \"the\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"the\", \"word_idx\": \"1\", \"dep_parent\": \"6\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27264\", \"word\": \"developed\", \"dep_label\": \"amod\", \"pos\": \"VBN\", \"lemma\": \"develop\", \"word_idx\": \"3\", \"dep_parent\": \"6\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27258\", \"word\": \"fully\", \"dep_label\": \"advmod\", \"pos\": \"RB\", \"lemma\": \"fully\", \"word_idx\": \"2\", \"dep_parent\": \"4\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"27274\", \"word\": \"ovule\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"ovule\", \"word_idx\": \"4\", \"dep_parent\": \"6\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"27307\", \"word\": \"phenotype\", \"dep_label\": \"nsubj\", \"pos\": \"NN\", \"lemma\": \"phenotype\", \"word_idx\": \"11\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27286\", \"word\": \"the\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"the\", \"word_idx\": \"6\", \"dep_parent\": \"12\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27290\", \"word\": \"_\", \"dep_label\": \"nummod\", \"pos\": \"CD\", \"lemma\": \"_\", \"word_idx\": \"7\", \"dep_parent\": \"12\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27291\", \"word\": \"spl/nzz\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"spl/nzz\", \"word_idx\": \"8\", \"dep_parent\": \"12\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27298\", \"word\": \"_\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"_\", \"word_idx\": \"9\", \"dep_parent\": \"12\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27300\", \"word\": \"mutant\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"mutant\", \"word_idx\": \"10\", \"dep_parent\": \"12\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"27383\", \"word\": \"characterized\", \"dep_label\": \"ccomp\", \"pos\": \"VBN\", \"lemma\": \"characterize\", \"word_idx\": \"29\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27327\", \"word\": \"that\", \"dep_label\": \"nsubjpass\", \"pos\": \"DT\", \"lemma\": \"that\", \"word_idx\": \"13\", \"dep_parent\": \"30\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27341\", \"word\": \"_\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"_\", \"word_idx\": \"17\", \"dep_parent\": \"14\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27332\", \"word\": \"of\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"of\", \"word_idx\": \"14\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27335\", \"word\": \"_\", \"dep_label\": \"nummod\", \"pos\": \"CD\", \"lemma\": \"_\", \"word_idx\": \"15\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27336\", \"word\": \"ashh2\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"ashh2\", \"word_idx\": \"16\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27342\", \"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"18\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27344\", \"word\": \"but\", \"dep_label\": \"cc\", \"pos\": \"CC\", \"lemma\": \"but\", \"word_idx\": \"19\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27351\", \"word\": \"contrast\", \"dep_label\": \"conj\", \"pos\": \"NN\", \"lemma\": \"contrast\", \"word_idx\": \"21\", \"dep_parent\": \"18\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27348\", \"word\": \"in\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"in\", \"word_idx\": \"20\", \"dep_parent\": \"22\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27364\", \"word\": \"ashh2\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"ashh2\", \"word_idx\": \"24\", \"dep_parent\": \"22\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27360\", \"word\": \"to\", \"dep_label\": \"case\", \"pos\": \"TO\", \"lemma\": \"to\", \"word_idx\": \"22\", \"dep_parent\": \"25\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27363\", \"word\": \"_\", \"dep_label\": \"amod\", \"pos\": \"VB\", \"lemma\": \"_\", \"word_idx\": \"23\", \"dep_parent\": \"25\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27369\", \"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"25\", \"dep_parent\": \"25\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27378\", \"word\": \"_\", \"dep_label\": \"appos\", \"pos\": \"NN\", \"lemma\": \"_\", \"word_idx\": \"27\", \"dep_parent\": \"25\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27371\", \"word\": \"spl/nzz\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"spl/nzz\", \"word_idx\": \"26\", \"dep_parent\": \"28\"}, \"children\": []}]}]}]}]}]}, {\"attrib\": {\"token_idx\": \"27380\", \"word\": \"is\", \"dep_label\": \"auxpass\", \"pos\": \"VBZ\", \"lemma\": \"be\", \"word_idx\": \"28\", \"dep_parent\": \"30\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27404\", \"word\": \"absence\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"absence\", \"word_idx\": \"32\", \"dep_parent\": \"30\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27397\", \"word\": \"by\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"by\", \"word_idx\": \"30\", \"dep_parent\": \"33\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27400\", \"word\": \"the\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"the\", \"word_idx\": \"31\", \"dep_parent\": \"33\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27417\", \"word\": \"MMC\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"mmc\", \"word_idx\": \"35\", \"dep_parent\": \"33\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27412\", \"word\": \"of\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"of\", \"word_idx\": \"33\", \"dep_parent\": \"36\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27415\", \"word\": \"a\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"a\", \"word_idx\": \"34\", \"dep_parent\": \"36\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"27433\", \"word\": \"stage\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"stage\", \"word_idx\": \"39\", \"dep_parent\": \"33\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27421\", \"word\": \"at\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"at\", \"word_idx\": \"36\", \"dep_parent\": \"40\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27424\", \"word\": \"an\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"a\", \"word_idx\": \"37\", \"dep_parent\": \"40\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27427\", \"word\": \"early\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"early\", \"word_idx\": \"38\", \"dep_parent\": \"40\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27448\", \"word\": \"development\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"development\", \"word_idx\": \"42\", \"dep_parent\": \"40\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27439\", \"word\": \"of\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"of\", \"word_idx\": \"40\", \"dep_parent\": \"43\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27442\", \"word\": \"ovule\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"ovule\", \"word_idx\": \"41\", \"dep_parent\": \"43\"}, \"children\": []}]}]}]}]}, {\"attrib\": {\"token_idx\": \"27459\", \"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"43\", \"dep_parent\": \"13\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27466\", \"word\": \"preventing\", \"dep_label\": \"xcomp\", \"pos\": \"VBG\", \"lemma\": \"prevent\", \"word_idx\": \"45\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27461\", \"word\": \"thus\", \"dep_label\": \"advmod\", \"pos\": \"RB\", \"lemma\": \"thus\", \"word_idx\": \"44\", \"dep_parent\": \"46\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27488\", \"word\": \"formation\", \"dep_label\": \"dobj\", \"pos\": \"NN\", \"lemma\": \"formation\", \"word_idx\": \"48\", \"dep_parent\": \"46\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27477\", \"word\": \"embryo\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"embryo\", \"word_idx\": \"46\", \"dep_parent\": \"49\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27484\", \"word\": \"sac\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"sac\", \"word_idx\": \"47\", \"dep_parent\": \"49\"}, \"children\": []}]}]}, {\"attrib\": {\"token_idx\": \"27497\", \"word\": \".\", \"dep_label\": \"punct\", \"pos\": \".\", \"lemma\": \".\", \"word_idx\": \"49\", \"dep_parent\": \"13\"}, \"children\": []}]};\n",
       "var highlightIdxs = [[16], [31, 32, 33, 34, 35]];\n",
       "\n",
       "// Highlight words / nodes\n",
       "var COLORS = [\"#ff5c33\", \"#ffcc00\", \"#33cc33\", \"#3399ff\"];\n",
       "function highlightWords() {\n",
       "  for (var i=0; i < highlightIdxs.length; i++) {\n",
       "    var c = COLORS[i];\n",
       "    var idxs = highlightIdxs[i];\n",
       "    for (var j=0; j < idxs.length; j++) {\n",
       "      d3.selectAll(\".word-\"+chartId+\"-\"+idxs[j]).style(\"stroke\", c).style(\"background\", c);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "// Constants\n",
       "var margin = {top: 20, right: 20, bottom: 20, left: 20},\n",
       "width = 800 - margin.left - margin.right,\n",
       "height = 350 - margin.top - margin.bottom,\n",
       "R = 5;\n",
       "\n",
       "// Create the d3 tree object\n",
       "var tree = d3.layout.tree()\n",
       "  .size([width, height]);\n",
       "\n",
       "// Create the svg canvas\n",
       "var svg = d3.select(\"#tree-chart-\" + chartId)\n",
       "  .append(\"svg\")\n",
       "  .attr(\"width\", width + margin.left + margin.right)\n",
       "  .attr(\"height\", height + margin.top + margin.bottom)\n",
       "  .append(\"g\")\n",
       "  .attr(\"transform\", \"translate(\" + margin.left + \",\" + margin.top + \")\");\n",
       "\n",
       "function renderTree() {\n",
       "  var nodes = tree.nodes(root),\n",
       "  edges = tree.links(nodes);\n",
       "\n",
       "  // Place the nodes\n",
       "  var nodeGroups = svg.selectAll(\"g.node\")\n",
       "    .data(nodes)\n",
       "    .enter().append(\"g\")\n",
       "    .attr(\"class\", \"node\")\n",
       "    .attr(\"transform\", function(d) { return \"translate(\" + d.x + \",\" + d.y + \")\"; });\n",
       "       \n",
       "  // Append circles\n",
       "  nodeGroups.append(\"circle\")\n",
       "    //.on(\"click\", function() {\n",
       "    //  d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"r\", R)\n",
       "    .attr(\"class\", function(d) { return \"word-\"+chartId+\"-\"+d.attrib.word_idx; });\n",
       "     \n",
       "  // Append the actual word\n",
       "  nodeGroups.append(\"text\")\n",
       "    .text(function(d) { return d.attrib.word; })\n",
       "    .attr(\"text-anchor\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? \"start\" : \"middle\"; })\n",
       "    .attr(\"dx\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? R + 3 : 0; })\n",
       "    .attr(\"dy\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? 0 : 3*R + 3; });\n",
       "\n",
       "  // Place the edges\n",
       "  var edgePaths = svg.selectAll(\"path\")\n",
       "    .data(edges)\n",
       "    .enter().append(\"path\")\n",
       "    .attr(\"class\", \"edge\")\n",
       "    .on(\"click\", function() {\n",
       "      d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"d\", d3.svg.diagonal());\n",
       "}\n",
       "\n",
       "renderTree();\n",
       "highlightWords();\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[16] [40, 41, 42] At the fully developed ovule stage the _ spl/nzz _ mutant phenotype resembles that of _ ashh2 _ , but in contrast to _ ashh2 , spl/nzz _ is characterized by the absence of a MMC at an early stage of ovule development , thus preventing embryo sac formation .\n",
      "At the fully developed ovule stage the _ spl/nzz _ mutant phenotype resembles that of _ {{GeneName}} _ , but in contrast to _ ashh2 , spl/nzz _ is characterized by the absence of a MMC at an early stage {{PhenoName}} , thus preventing embryo sac formation .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".node {\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".node circle {\n",
       "  fill: #fff;\n",
       "  stroke: steelblue;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "\n",
       ".node text {\n",
       "  font: 12px sans-serif;\n",
       "}\n",
       "\n",
       ".edge {\n",
       "  fill: none;\n",
       "  stroke: #ccc;\n",
       "  stroke-width: 2px;\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".highlight {\n",
       "  stroke: red;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<!--Provide the canvas id (twice) and the words via python string formatting here--!>\n",
       "<div id=\"tree-chart-5982185982202176091\"></div>\n",
       "<div id=\"raw-seq-5982185982202176091\">\n",
       "<span class=\"word-5982185982202176091-0\">At</span> <span class=\"word-5982185982202176091-1\">the</span> <span class=\"word-5982185982202176091-2\">fully</span> <span class=\"word-5982185982202176091-3\">developed</span> <span class=\"word-5982185982202176091-4\">ovule</span> <span class=\"word-5982185982202176091-5\">stage</span> <span class=\"word-5982185982202176091-6\">the</span> <span class=\"word-5982185982202176091-7\">_</span> <span class=\"word-5982185982202176091-8\">spl/nzz</span> <span class=\"word-5982185982202176091-9\">_</span> <span class=\"word-5982185982202176091-10\">mutant</span> <span class=\"word-5982185982202176091-11\">phenotype</span> <span class=\"word-5982185982202176091-12\">resembles</span> <span class=\"word-5982185982202176091-13\">that</span> <span class=\"word-5982185982202176091-14\">of</span> <span class=\"word-5982185982202176091-15\">_</span> <span class=\"word-5982185982202176091-16\">ashh2</span> <span class=\"word-5982185982202176091-17\">_</span> <span class=\"word-5982185982202176091-18\">,</span> <span class=\"word-5982185982202176091-19\">but</span> <span class=\"word-5982185982202176091-20\">in</span> <span class=\"word-5982185982202176091-21\">contrast</span> <span class=\"word-5982185982202176091-22\">to</span> <span class=\"word-5982185982202176091-23\">_</span> <span class=\"word-5982185982202176091-24\">ashh2</span> <span class=\"word-5982185982202176091-25\">,</span> <span class=\"word-5982185982202176091-26\">spl/nzz</span> <span class=\"word-5982185982202176091-27\">_</span> <span class=\"word-5982185982202176091-28\">is</span> <span class=\"word-5982185982202176091-29\">characterized</span> <span class=\"word-5982185982202176091-30\">by</span> <span class=\"word-5982185982202176091-31\">the</span> <span class=\"word-5982185982202176091-32\">absence</span> <span class=\"word-5982185982202176091-33\">of</span> <span class=\"word-5982185982202176091-34\">a</span> <span class=\"word-5982185982202176091-35\">MMC</span> <span class=\"word-5982185982202176091-36\">at</span> <span class=\"word-5982185982202176091-37\">an</span> <span class=\"word-5982185982202176091-38\">early</span> <span class=\"word-5982185982202176091-39\">stage</span> <span class=\"word-5982185982202176091-40\">of</span> <span class=\"word-5982185982202176091-41\">ovule</span> <span class=\"word-5982185982202176091-42\">development</span> <span class=\"word-5982185982202176091-43\">,</span> <span class=\"word-5982185982202176091-44\">thus</span> <span class=\"word-5982185982202176091-45\">preventing</span> <span class=\"word-5982185982202176091-46\">embryo</span> <span class=\"word-5982185982202176091-47\">sac</span> <span class=\"word-5982185982202176091-48\">formation</span> <span class=\"word-5982185982202176091-49\">.</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "$.getScript(\"http://d3js.org/d3.v3.min.js\", function () {\n",
       "// See http://bl.ocks.org/d3noob/8375092\n",
       "// Three vars need to be provided via python string formatting:\n",
       "var chartId = \"5982185982202176091\";\n",
       "var root = {\"attrib\": {\"token_idx\": \"27317\", \"word\": \"resembles\", \"dep_label\": \"ROOT\", \"pos\": \"VBZ\", \"lemma\": \"resemble\", \"word_idx\": \"12\", \"dep_parent\": \"0\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27280\", \"word\": \"stage\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"stage\", \"word_idx\": \"5\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27251\", \"word\": \"At\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"at\", \"word_idx\": \"0\", \"dep_parent\": \"6\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27254\", \"word\": \"the\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"the\", \"word_idx\": \"1\", \"dep_parent\": \"6\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27264\", \"word\": \"developed\", \"dep_label\": \"amod\", \"pos\": \"VBN\", \"lemma\": \"develop\", \"word_idx\": \"3\", \"dep_parent\": \"6\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27258\", \"word\": \"fully\", \"dep_label\": \"advmod\", \"pos\": \"RB\", \"lemma\": \"fully\", \"word_idx\": \"2\", \"dep_parent\": \"4\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"27274\", \"word\": \"ovule\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"ovule\", \"word_idx\": \"4\", \"dep_parent\": \"6\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"27307\", \"word\": \"phenotype\", \"dep_label\": \"nsubj\", \"pos\": \"NN\", \"lemma\": \"phenotype\", \"word_idx\": \"11\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27286\", \"word\": \"the\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"the\", \"word_idx\": \"6\", \"dep_parent\": \"12\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27290\", \"word\": \"_\", \"dep_label\": \"nummod\", \"pos\": \"CD\", \"lemma\": \"_\", \"word_idx\": \"7\", \"dep_parent\": \"12\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27291\", \"word\": \"spl/nzz\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"spl/nzz\", \"word_idx\": \"8\", \"dep_parent\": \"12\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27298\", \"word\": \"_\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"_\", \"word_idx\": \"9\", \"dep_parent\": \"12\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27300\", \"word\": \"mutant\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"mutant\", \"word_idx\": \"10\", \"dep_parent\": \"12\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"27383\", \"word\": \"characterized\", \"dep_label\": \"ccomp\", \"pos\": \"VBN\", \"lemma\": \"characterize\", \"word_idx\": \"29\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27327\", \"word\": \"that\", \"dep_label\": \"nsubjpass\", \"pos\": \"DT\", \"lemma\": \"that\", \"word_idx\": \"13\", \"dep_parent\": \"30\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27341\", \"word\": \"_\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"_\", \"word_idx\": \"17\", \"dep_parent\": \"14\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27332\", \"word\": \"of\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"of\", \"word_idx\": \"14\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27335\", \"word\": \"_\", \"dep_label\": \"nummod\", \"pos\": \"CD\", \"lemma\": \"_\", \"word_idx\": \"15\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27336\", \"word\": \"ashh2\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"ashh2\", \"word_idx\": \"16\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27342\", \"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"18\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27344\", \"word\": \"but\", \"dep_label\": \"cc\", \"pos\": \"CC\", \"lemma\": \"but\", \"word_idx\": \"19\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27351\", \"word\": \"contrast\", \"dep_label\": \"conj\", \"pos\": \"NN\", \"lemma\": \"contrast\", \"word_idx\": \"21\", \"dep_parent\": \"18\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27348\", \"word\": \"in\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"in\", \"word_idx\": \"20\", \"dep_parent\": \"22\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27364\", \"word\": \"ashh2\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"ashh2\", \"word_idx\": \"24\", \"dep_parent\": \"22\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27360\", \"word\": \"to\", \"dep_label\": \"case\", \"pos\": \"TO\", \"lemma\": \"to\", \"word_idx\": \"22\", \"dep_parent\": \"25\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27363\", \"word\": \"_\", \"dep_label\": \"amod\", \"pos\": \"VB\", \"lemma\": \"_\", \"word_idx\": \"23\", \"dep_parent\": \"25\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27369\", \"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"25\", \"dep_parent\": \"25\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27378\", \"word\": \"_\", \"dep_label\": \"appos\", \"pos\": \"NN\", \"lemma\": \"_\", \"word_idx\": \"27\", \"dep_parent\": \"25\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27371\", \"word\": \"spl/nzz\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"spl/nzz\", \"word_idx\": \"26\", \"dep_parent\": \"28\"}, \"children\": []}]}]}]}]}]}, {\"attrib\": {\"token_idx\": \"27380\", \"word\": \"is\", \"dep_label\": \"auxpass\", \"pos\": \"VBZ\", \"lemma\": \"be\", \"word_idx\": \"28\", \"dep_parent\": \"30\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27404\", \"word\": \"absence\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"absence\", \"word_idx\": \"32\", \"dep_parent\": \"30\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27397\", \"word\": \"by\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"by\", \"word_idx\": \"30\", \"dep_parent\": \"33\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27400\", \"word\": \"the\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"the\", \"word_idx\": \"31\", \"dep_parent\": \"33\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27417\", \"word\": \"MMC\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"mmc\", \"word_idx\": \"35\", \"dep_parent\": \"33\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27412\", \"word\": \"of\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"of\", \"word_idx\": \"33\", \"dep_parent\": \"36\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27415\", \"word\": \"a\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"a\", \"word_idx\": \"34\", \"dep_parent\": \"36\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"27433\", \"word\": \"stage\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"stage\", \"word_idx\": \"39\", \"dep_parent\": \"33\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27421\", \"word\": \"at\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"at\", \"word_idx\": \"36\", \"dep_parent\": \"40\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27424\", \"word\": \"an\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"a\", \"word_idx\": \"37\", \"dep_parent\": \"40\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27427\", \"word\": \"early\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"early\", \"word_idx\": \"38\", \"dep_parent\": \"40\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27448\", \"word\": \"development\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"development\", \"word_idx\": \"42\", \"dep_parent\": \"40\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27439\", \"word\": \"of\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"of\", \"word_idx\": \"40\", \"dep_parent\": \"43\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27442\", \"word\": \"ovule\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"ovule\", \"word_idx\": \"41\", \"dep_parent\": \"43\"}, \"children\": []}]}]}]}]}, {\"attrib\": {\"token_idx\": \"27459\", \"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"43\", \"dep_parent\": \"13\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27466\", \"word\": \"preventing\", \"dep_label\": \"xcomp\", \"pos\": \"VBG\", \"lemma\": \"prevent\", \"word_idx\": \"45\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27461\", \"word\": \"thus\", \"dep_label\": \"advmod\", \"pos\": \"RB\", \"lemma\": \"thus\", \"word_idx\": \"44\", \"dep_parent\": \"46\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27488\", \"word\": \"formation\", \"dep_label\": \"dobj\", \"pos\": \"NN\", \"lemma\": \"formation\", \"word_idx\": \"48\", \"dep_parent\": \"46\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27477\", \"word\": \"embryo\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"embryo\", \"word_idx\": \"46\", \"dep_parent\": \"49\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27484\", \"word\": \"sac\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"sac\", \"word_idx\": \"47\", \"dep_parent\": \"49\"}, \"children\": []}]}]}, {\"attrib\": {\"token_idx\": \"27497\", \"word\": \".\", \"dep_label\": \"punct\", \"pos\": \".\", \"lemma\": \".\", \"word_idx\": \"49\", \"dep_parent\": \"13\"}, \"children\": []}]};\n",
       "var highlightIdxs = [[16], [40, 41, 42]];\n",
       "\n",
       "// Highlight words / nodes\n",
       "var COLORS = [\"#ff5c33\", \"#ffcc00\", \"#33cc33\", \"#3399ff\"];\n",
       "function highlightWords() {\n",
       "  for (var i=0; i < highlightIdxs.length; i++) {\n",
       "    var c = COLORS[i];\n",
       "    var idxs = highlightIdxs[i];\n",
       "    for (var j=0; j < idxs.length; j++) {\n",
       "      d3.selectAll(\".word-\"+chartId+\"-\"+idxs[j]).style(\"stroke\", c).style(\"background\", c);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "// Constants\n",
       "var margin = {top: 20, right: 20, bottom: 20, left: 20},\n",
       "width = 800 - margin.left - margin.right,\n",
       "height = 350 - margin.top - margin.bottom,\n",
       "R = 5;\n",
       "\n",
       "// Create the d3 tree object\n",
       "var tree = d3.layout.tree()\n",
       "  .size([width, height]);\n",
       "\n",
       "// Create the svg canvas\n",
       "var svg = d3.select(\"#tree-chart-\" + chartId)\n",
       "  .append(\"svg\")\n",
       "  .attr(\"width\", width + margin.left + margin.right)\n",
       "  .attr(\"height\", height + margin.top + margin.bottom)\n",
       "  .append(\"g\")\n",
       "  .attr(\"transform\", \"translate(\" + margin.left + \",\" + margin.top + \")\");\n",
       "\n",
       "function renderTree() {\n",
       "  var nodes = tree.nodes(root),\n",
       "  edges = tree.links(nodes);\n",
       "\n",
       "  // Place the nodes\n",
       "  var nodeGroups = svg.selectAll(\"g.node\")\n",
       "    .data(nodes)\n",
       "    .enter().append(\"g\")\n",
       "    .attr(\"class\", \"node\")\n",
       "    .attr(\"transform\", function(d) { return \"translate(\" + d.x + \",\" + d.y + \")\"; });\n",
       "       \n",
       "  // Append circles\n",
       "  nodeGroups.append(\"circle\")\n",
       "    //.on(\"click\", function() {\n",
       "    //  d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"r\", R)\n",
       "    .attr(\"class\", function(d) { return \"word-\"+chartId+\"-\"+d.attrib.word_idx; });\n",
       "     \n",
       "  // Append the actual word\n",
       "  nodeGroups.append(\"text\")\n",
       "    .text(function(d) { return d.attrib.word; })\n",
       "    .attr(\"text-anchor\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? \"start\" : \"middle\"; })\n",
       "    .attr(\"dx\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? R + 3 : 0; })\n",
       "    .attr(\"dy\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? 0 : 3*R + 3; });\n",
       "\n",
       "  // Place the edges\n",
       "  var edgePaths = svg.selectAll(\"path\")\n",
       "    .data(edges)\n",
       "    .enter().append(\"path\")\n",
       "    .attr(\"class\", \"edge\")\n",
       "    .on(\"click\", function() {\n",
       "      d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"d\", d3.svg.diagonal());\n",
       "}\n",
       "\n",
       "renderTree();\n",
       "highlightWords();\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[16] [46, 47, 48] At the fully developed ovule stage the _ spl/nzz _ mutant phenotype resembles that of _ ashh2 _ , but in contrast to _ ashh2 , spl/nzz _ is characterized by the absence of a MMC at an early stage of ovule development , thus preventing embryo sac formation .\n",
      "At the fully developed ovule stage the _ spl/nzz _ mutant phenotype resembles that of _ {{GeneName}} _ , but in contrast to _ ashh2 , spl/nzz _ is characterized by the absence of a MMC at an early stage of ovule development , thus preventing {{PhenoName}} .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".node {\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".node circle {\n",
       "  fill: #fff;\n",
       "  stroke: steelblue;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "\n",
       ".node text {\n",
       "  font: 12px sans-serif;\n",
       "}\n",
       "\n",
       ".edge {\n",
       "  fill: none;\n",
       "  stroke: #ccc;\n",
       "  stroke-width: 2px;\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".highlight {\n",
       "  stroke: red;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<!--Provide the canvas id (twice) and the words via python string formatting here--!>\n",
       "<div id=\"tree-chart-5982185982202176091\"></div>\n",
       "<div id=\"raw-seq-5982185982202176091\">\n",
       "<span class=\"word-5982185982202176091-0\">At</span> <span class=\"word-5982185982202176091-1\">the</span> <span class=\"word-5982185982202176091-2\">fully</span> <span class=\"word-5982185982202176091-3\">developed</span> <span class=\"word-5982185982202176091-4\">ovule</span> <span class=\"word-5982185982202176091-5\">stage</span> <span class=\"word-5982185982202176091-6\">the</span> <span class=\"word-5982185982202176091-7\">_</span> <span class=\"word-5982185982202176091-8\">spl/nzz</span> <span class=\"word-5982185982202176091-9\">_</span> <span class=\"word-5982185982202176091-10\">mutant</span> <span class=\"word-5982185982202176091-11\">phenotype</span> <span class=\"word-5982185982202176091-12\">resembles</span> <span class=\"word-5982185982202176091-13\">that</span> <span class=\"word-5982185982202176091-14\">of</span> <span class=\"word-5982185982202176091-15\">_</span> <span class=\"word-5982185982202176091-16\">ashh2</span> <span class=\"word-5982185982202176091-17\">_</span> <span class=\"word-5982185982202176091-18\">,</span> <span class=\"word-5982185982202176091-19\">but</span> <span class=\"word-5982185982202176091-20\">in</span> <span class=\"word-5982185982202176091-21\">contrast</span> <span class=\"word-5982185982202176091-22\">to</span> <span class=\"word-5982185982202176091-23\">_</span> <span class=\"word-5982185982202176091-24\">ashh2</span> <span class=\"word-5982185982202176091-25\">,</span> <span class=\"word-5982185982202176091-26\">spl/nzz</span> <span class=\"word-5982185982202176091-27\">_</span> <span class=\"word-5982185982202176091-28\">is</span> <span class=\"word-5982185982202176091-29\">characterized</span> <span class=\"word-5982185982202176091-30\">by</span> <span class=\"word-5982185982202176091-31\">the</span> <span class=\"word-5982185982202176091-32\">absence</span> <span class=\"word-5982185982202176091-33\">of</span> <span class=\"word-5982185982202176091-34\">a</span> <span class=\"word-5982185982202176091-35\">MMC</span> <span class=\"word-5982185982202176091-36\">at</span> <span class=\"word-5982185982202176091-37\">an</span> <span class=\"word-5982185982202176091-38\">early</span> <span class=\"word-5982185982202176091-39\">stage</span> <span class=\"word-5982185982202176091-40\">of</span> <span class=\"word-5982185982202176091-41\">ovule</span> <span class=\"word-5982185982202176091-42\">development</span> <span class=\"word-5982185982202176091-43\">,</span> <span class=\"word-5982185982202176091-44\">thus</span> <span class=\"word-5982185982202176091-45\">preventing</span> <span class=\"word-5982185982202176091-46\">embryo</span> <span class=\"word-5982185982202176091-47\">sac</span> <span class=\"word-5982185982202176091-48\">formation</span> <span class=\"word-5982185982202176091-49\">.</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "$.getScript(\"http://d3js.org/d3.v3.min.js\", function () {\n",
       "// See http://bl.ocks.org/d3noob/8375092\n",
       "// Three vars need to be provided via python string formatting:\n",
       "var chartId = \"5982185982202176091\";\n",
       "var root = {\"attrib\": {\"token_idx\": \"27317\", \"word\": \"resembles\", \"dep_label\": \"ROOT\", \"pos\": \"VBZ\", \"lemma\": \"resemble\", \"word_idx\": \"12\", \"dep_parent\": \"0\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27280\", \"word\": \"stage\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"stage\", \"word_idx\": \"5\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27251\", \"word\": \"At\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"at\", \"word_idx\": \"0\", \"dep_parent\": \"6\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27254\", \"word\": \"the\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"the\", \"word_idx\": \"1\", \"dep_parent\": \"6\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27264\", \"word\": \"developed\", \"dep_label\": \"amod\", \"pos\": \"VBN\", \"lemma\": \"develop\", \"word_idx\": \"3\", \"dep_parent\": \"6\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27258\", \"word\": \"fully\", \"dep_label\": \"advmod\", \"pos\": \"RB\", \"lemma\": \"fully\", \"word_idx\": \"2\", \"dep_parent\": \"4\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"27274\", \"word\": \"ovule\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"ovule\", \"word_idx\": \"4\", \"dep_parent\": \"6\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"27307\", \"word\": \"phenotype\", \"dep_label\": \"nsubj\", \"pos\": \"NN\", \"lemma\": \"phenotype\", \"word_idx\": \"11\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27286\", \"word\": \"the\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"the\", \"word_idx\": \"6\", \"dep_parent\": \"12\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27290\", \"word\": \"_\", \"dep_label\": \"nummod\", \"pos\": \"CD\", \"lemma\": \"_\", \"word_idx\": \"7\", \"dep_parent\": \"12\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27291\", \"word\": \"spl/nzz\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"spl/nzz\", \"word_idx\": \"8\", \"dep_parent\": \"12\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27298\", \"word\": \"_\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"_\", \"word_idx\": \"9\", \"dep_parent\": \"12\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27300\", \"word\": \"mutant\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"mutant\", \"word_idx\": \"10\", \"dep_parent\": \"12\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"27383\", \"word\": \"characterized\", \"dep_label\": \"ccomp\", \"pos\": \"VBN\", \"lemma\": \"characterize\", \"word_idx\": \"29\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27327\", \"word\": \"that\", \"dep_label\": \"nsubjpass\", \"pos\": \"DT\", \"lemma\": \"that\", \"word_idx\": \"13\", \"dep_parent\": \"30\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27341\", \"word\": \"_\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"_\", \"word_idx\": \"17\", \"dep_parent\": \"14\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27332\", \"word\": \"of\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"of\", \"word_idx\": \"14\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27335\", \"word\": \"_\", \"dep_label\": \"nummod\", \"pos\": \"CD\", \"lemma\": \"_\", \"word_idx\": \"15\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27336\", \"word\": \"ashh2\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"ashh2\", \"word_idx\": \"16\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27342\", \"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"18\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27344\", \"word\": \"but\", \"dep_label\": \"cc\", \"pos\": \"CC\", \"lemma\": \"but\", \"word_idx\": \"19\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27351\", \"word\": \"contrast\", \"dep_label\": \"conj\", \"pos\": \"NN\", \"lemma\": \"contrast\", \"word_idx\": \"21\", \"dep_parent\": \"18\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27348\", \"word\": \"in\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"in\", \"word_idx\": \"20\", \"dep_parent\": \"22\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27364\", \"word\": \"ashh2\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"ashh2\", \"word_idx\": \"24\", \"dep_parent\": \"22\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27360\", \"word\": \"to\", \"dep_label\": \"case\", \"pos\": \"TO\", \"lemma\": \"to\", \"word_idx\": \"22\", \"dep_parent\": \"25\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27363\", \"word\": \"_\", \"dep_label\": \"amod\", \"pos\": \"VB\", \"lemma\": \"_\", \"word_idx\": \"23\", \"dep_parent\": \"25\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27369\", \"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"25\", \"dep_parent\": \"25\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27378\", \"word\": \"_\", \"dep_label\": \"appos\", \"pos\": \"NN\", \"lemma\": \"_\", \"word_idx\": \"27\", \"dep_parent\": \"25\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27371\", \"word\": \"spl/nzz\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"spl/nzz\", \"word_idx\": \"26\", \"dep_parent\": \"28\"}, \"children\": []}]}]}]}]}]}, {\"attrib\": {\"token_idx\": \"27380\", \"word\": \"is\", \"dep_label\": \"auxpass\", \"pos\": \"VBZ\", \"lemma\": \"be\", \"word_idx\": \"28\", \"dep_parent\": \"30\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27404\", \"word\": \"absence\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"absence\", \"word_idx\": \"32\", \"dep_parent\": \"30\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27397\", \"word\": \"by\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"by\", \"word_idx\": \"30\", \"dep_parent\": \"33\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27400\", \"word\": \"the\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"the\", \"word_idx\": \"31\", \"dep_parent\": \"33\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27417\", \"word\": \"MMC\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"mmc\", \"word_idx\": \"35\", \"dep_parent\": \"33\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27412\", \"word\": \"of\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"of\", \"word_idx\": \"33\", \"dep_parent\": \"36\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27415\", \"word\": \"a\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"a\", \"word_idx\": \"34\", \"dep_parent\": \"36\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"27433\", \"word\": \"stage\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"stage\", \"word_idx\": \"39\", \"dep_parent\": \"33\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27421\", \"word\": \"at\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"at\", \"word_idx\": \"36\", \"dep_parent\": \"40\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27424\", \"word\": \"an\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"a\", \"word_idx\": \"37\", \"dep_parent\": \"40\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27427\", \"word\": \"early\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"early\", \"word_idx\": \"38\", \"dep_parent\": \"40\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27448\", \"word\": \"development\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"development\", \"word_idx\": \"42\", \"dep_parent\": \"40\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27439\", \"word\": \"of\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"of\", \"word_idx\": \"40\", \"dep_parent\": \"43\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27442\", \"word\": \"ovule\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"ovule\", \"word_idx\": \"41\", \"dep_parent\": \"43\"}, \"children\": []}]}]}]}]}, {\"attrib\": {\"token_idx\": \"27459\", \"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"43\", \"dep_parent\": \"13\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27466\", \"word\": \"preventing\", \"dep_label\": \"xcomp\", \"pos\": \"VBG\", \"lemma\": \"prevent\", \"word_idx\": \"45\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27461\", \"word\": \"thus\", \"dep_label\": \"advmod\", \"pos\": \"RB\", \"lemma\": \"thus\", \"word_idx\": \"44\", \"dep_parent\": \"46\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27488\", \"word\": \"formation\", \"dep_label\": \"dobj\", \"pos\": \"NN\", \"lemma\": \"formation\", \"word_idx\": \"48\", \"dep_parent\": \"46\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27477\", \"word\": \"embryo\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"embryo\", \"word_idx\": \"46\", \"dep_parent\": \"49\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27484\", \"word\": \"sac\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"sac\", \"word_idx\": \"47\", \"dep_parent\": \"49\"}, \"children\": []}]}]}, {\"attrib\": {\"token_idx\": \"27497\", \"word\": \".\", \"dep_label\": \"punct\", \"pos\": \".\", \"lemma\": \".\", \"word_idx\": \"49\", \"dep_parent\": \"13\"}, \"children\": []}]};\n",
       "var highlightIdxs = [[16], [46, 47, 48]];\n",
       "\n",
       "// Highlight words / nodes\n",
       "var COLORS = [\"#ff5c33\", \"#ffcc00\", \"#33cc33\", \"#3399ff\"];\n",
       "function highlightWords() {\n",
       "  for (var i=0; i < highlightIdxs.length; i++) {\n",
       "    var c = COLORS[i];\n",
       "    var idxs = highlightIdxs[i];\n",
       "    for (var j=0; j < idxs.length; j++) {\n",
       "      d3.selectAll(\".word-\"+chartId+\"-\"+idxs[j]).style(\"stroke\", c).style(\"background\", c);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "// Constants\n",
       "var margin = {top: 20, right: 20, bottom: 20, left: 20},\n",
       "width = 800 - margin.left - margin.right,\n",
       "height = 350 - margin.top - margin.bottom,\n",
       "R = 5;\n",
       "\n",
       "// Create the d3 tree object\n",
       "var tree = d3.layout.tree()\n",
       "  .size([width, height]);\n",
       "\n",
       "// Create the svg canvas\n",
       "var svg = d3.select(\"#tree-chart-\" + chartId)\n",
       "  .append(\"svg\")\n",
       "  .attr(\"width\", width + margin.left + margin.right)\n",
       "  .attr(\"height\", height + margin.top + margin.bottom)\n",
       "  .append(\"g\")\n",
       "  .attr(\"transform\", \"translate(\" + margin.left + \",\" + margin.top + \")\");\n",
       "\n",
       "function renderTree() {\n",
       "  var nodes = tree.nodes(root),\n",
       "  edges = tree.links(nodes);\n",
       "\n",
       "  // Place the nodes\n",
       "  var nodeGroups = svg.selectAll(\"g.node\")\n",
       "    .data(nodes)\n",
       "    .enter().append(\"g\")\n",
       "    .attr(\"class\", \"node\")\n",
       "    .attr(\"transform\", function(d) { return \"translate(\" + d.x + \",\" + d.y + \")\"; });\n",
       "       \n",
       "  // Append circles\n",
       "  nodeGroups.append(\"circle\")\n",
       "    //.on(\"click\", function() {\n",
       "    //  d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"r\", R)\n",
       "    .attr(\"class\", function(d) { return \"word-\"+chartId+\"-\"+d.attrib.word_idx; });\n",
       "     \n",
       "  // Append the actual word\n",
       "  nodeGroups.append(\"text\")\n",
       "    .text(function(d) { return d.attrib.word; })\n",
       "    .attr(\"text-anchor\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? \"start\" : \"middle\"; })\n",
       "    .attr(\"dx\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? R + 3 : 0; })\n",
       "    .attr(\"dy\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? 0 : 3*R + 3; });\n",
       "\n",
       "  // Place the edges\n",
       "  var edgePaths = svg.selectAll(\"path\")\n",
       "    .data(edges)\n",
       "    .enter().append(\"path\")\n",
       "    .attr(\"class\", \"edge\")\n",
       "    .on(\"click\", function() {\n",
       "      d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"d\", d3.svg.diagonal());\n",
       "}\n",
       "\n",
       "renderTree();\n",
       "highlightWords();\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[24] [31, 32, 33, 34, 35] At the fully developed ovule stage the _ spl/nzz _ mutant phenotype resembles that of _ ashh2 _ , but in contrast to _ ashh2 , spl/nzz _ is characterized by the absence of a MMC at an early stage of ovule development , thus preventing embryo sac formation .\n",
      "At the fully developed ovule stage the _ spl/nzz _ mutant phenotype resembles that of _ ashh2 _ , but in contrast to _ {{GeneName}} , spl/nzz _ is characterized by {{PhenoName}} at an early stage of ovule development , thus preventing embryo sac formation .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".node {\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".node circle {\n",
       "  fill: #fff;\n",
       "  stroke: steelblue;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "\n",
       ".node text {\n",
       "  font: 12px sans-serif;\n",
       "}\n",
       "\n",
       ".edge {\n",
       "  fill: none;\n",
       "  stroke: #ccc;\n",
       "  stroke-width: 2px;\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".highlight {\n",
       "  stroke: red;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<!--Provide the canvas id (twice) and the words via python string formatting here--!>\n",
       "<div id=\"tree-chart-5982185982202176091\"></div>\n",
       "<div id=\"raw-seq-5982185982202176091\">\n",
       "<span class=\"word-5982185982202176091-0\">At</span> <span class=\"word-5982185982202176091-1\">the</span> <span class=\"word-5982185982202176091-2\">fully</span> <span class=\"word-5982185982202176091-3\">developed</span> <span class=\"word-5982185982202176091-4\">ovule</span> <span class=\"word-5982185982202176091-5\">stage</span> <span class=\"word-5982185982202176091-6\">the</span> <span class=\"word-5982185982202176091-7\">_</span> <span class=\"word-5982185982202176091-8\">spl/nzz</span> <span class=\"word-5982185982202176091-9\">_</span> <span class=\"word-5982185982202176091-10\">mutant</span> <span class=\"word-5982185982202176091-11\">phenotype</span> <span class=\"word-5982185982202176091-12\">resembles</span> <span class=\"word-5982185982202176091-13\">that</span> <span class=\"word-5982185982202176091-14\">of</span> <span class=\"word-5982185982202176091-15\">_</span> <span class=\"word-5982185982202176091-16\">ashh2</span> <span class=\"word-5982185982202176091-17\">_</span> <span class=\"word-5982185982202176091-18\">,</span> <span class=\"word-5982185982202176091-19\">but</span> <span class=\"word-5982185982202176091-20\">in</span> <span class=\"word-5982185982202176091-21\">contrast</span> <span class=\"word-5982185982202176091-22\">to</span> <span class=\"word-5982185982202176091-23\">_</span> <span class=\"word-5982185982202176091-24\">ashh2</span> <span class=\"word-5982185982202176091-25\">,</span> <span class=\"word-5982185982202176091-26\">spl/nzz</span> <span class=\"word-5982185982202176091-27\">_</span> <span class=\"word-5982185982202176091-28\">is</span> <span class=\"word-5982185982202176091-29\">characterized</span> <span class=\"word-5982185982202176091-30\">by</span> <span class=\"word-5982185982202176091-31\">the</span> <span class=\"word-5982185982202176091-32\">absence</span> <span class=\"word-5982185982202176091-33\">of</span> <span class=\"word-5982185982202176091-34\">a</span> <span class=\"word-5982185982202176091-35\">MMC</span> <span class=\"word-5982185982202176091-36\">at</span> <span class=\"word-5982185982202176091-37\">an</span> <span class=\"word-5982185982202176091-38\">early</span> <span class=\"word-5982185982202176091-39\">stage</span> <span class=\"word-5982185982202176091-40\">of</span> <span class=\"word-5982185982202176091-41\">ovule</span> <span class=\"word-5982185982202176091-42\">development</span> <span class=\"word-5982185982202176091-43\">,</span> <span class=\"word-5982185982202176091-44\">thus</span> <span class=\"word-5982185982202176091-45\">preventing</span> <span class=\"word-5982185982202176091-46\">embryo</span> <span class=\"word-5982185982202176091-47\">sac</span> <span class=\"word-5982185982202176091-48\">formation</span> <span class=\"word-5982185982202176091-49\">.</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "$.getScript(\"http://d3js.org/d3.v3.min.js\", function () {\n",
       "// See http://bl.ocks.org/d3noob/8375092\n",
       "// Three vars need to be provided via python string formatting:\n",
       "var chartId = \"5982185982202176091\";\n",
       "var root = {\"attrib\": {\"token_idx\": \"27317\", \"word\": \"resembles\", \"dep_label\": \"ROOT\", \"pos\": \"VBZ\", \"lemma\": \"resemble\", \"word_idx\": \"12\", \"dep_parent\": \"0\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27280\", \"word\": \"stage\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"stage\", \"word_idx\": \"5\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27251\", \"word\": \"At\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"at\", \"word_idx\": \"0\", \"dep_parent\": \"6\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27254\", \"word\": \"the\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"the\", \"word_idx\": \"1\", \"dep_parent\": \"6\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27264\", \"word\": \"developed\", \"dep_label\": \"amod\", \"pos\": \"VBN\", \"lemma\": \"develop\", \"word_idx\": \"3\", \"dep_parent\": \"6\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27258\", \"word\": \"fully\", \"dep_label\": \"advmod\", \"pos\": \"RB\", \"lemma\": \"fully\", \"word_idx\": \"2\", \"dep_parent\": \"4\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"27274\", \"word\": \"ovule\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"ovule\", \"word_idx\": \"4\", \"dep_parent\": \"6\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"27307\", \"word\": \"phenotype\", \"dep_label\": \"nsubj\", \"pos\": \"NN\", \"lemma\": \"phenotype\", \"word_idx\": \"11\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27286\", \"word\": \"the\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"the\", \"word_idx\": \"6\", \"dep_parent\": \"12\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27290\", \"word\": \"_\", \"dep_label\": \"nummod\", \"pos\": \"CD\", \"lemma\": \"_\", \"word_idx\": \"7\", \"dep_parent\": \"12\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27291\", \"word\": \"spl/nzz\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"spl/nzz\", \"word_idx\": \"8\", \"dep_parent\": \"12\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27298\", \"word\": \"_\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"_\", \"word_idx\": \"9\", \"dep_parent\": \"12\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27300\", \"word\": \"mutant\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"mutant\", \"word_idx\": \"10\", \"dep_parent\": \"12\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"27383\", \"word\": \"characterized\", \"dep_label\": \"ccomp\", \"pos\": \"VBN\", \"lemma\": \"characterize\", \"word_idx\": \"29\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27327\", \"word\": \"that\", \"dep_label\": \"nsubjpass\", \"pos\": \"DT\", \"lemma\": \"that\", \"word_idx\": \"13\", \"dep_parent\": \"30\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27341\", \"word\": \"_\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"_\", \"word_idx\": \"17\", \"dep_parent\": \"14\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27332\", \"word\": \"of\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"of\", \"word_idx\": \"14\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27335\", \"word\": \"_\", \"dep_label\": \"nummod\", \"pos\": \"CD\", \"lemma\": \"_\", \"word_idx\": \"15\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27336\", \"word\": \"ashh2\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"ashh2\", \"word_idx\": \"16\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27342\", \"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"18\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27344\", \"word\": \"but\", \"dep_label\": \"cc\", \"pos\": \"CC\", \"lemma\": \"but\", \"word_idx\": \"19\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27351\", \"word\": \"contrast\", \"dep_label\": \"conj\", \"pos\": \"NN\", \"lemma\": \"contrast\", \"word_idx\": \"21\", \"dep_parent\": \"18\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27348\", \"word\": \"in\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"in\", \"word_idx\": \"20\", \"dep_parent\": \"22\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27364\", \"word\": \"ashh2\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"ashh2\", \"word_idx\": \"24\", \"dep_parent\": \"22\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27360\", \"word\": \"to\", \"dep_label\": \"case\", \"pos\": \"TO\", \"lemma\": \"to\", \"word_idx\": \"22\", \"dep_parent\": \"25\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27363\", \"word\": \"_\", \"dep_label\": \"amod\", \"pos\": \"VB\", \"lemma\": \"_\", \"word_idx\": \"23\", \"dep_parent\": \"25\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27369\", \"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"25\", \"dep_parent\": \"25\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27378\", \"word\": \"_\", \"dep_label\": \"appos\", \"pos\": \"NN\", \"lemma\": \"_\", \"word_idx\": \"27\", \"dep_parent\": \"25\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27371\", \"word\": \"spl/nzz\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"spl/nzz\", \"word_idx\": \"26\", \"dep_parent\": \"28\"}, \"children\": []}]}]}]}]}]}, {\"attrib\": {\"token_idx\": \"27380\", \"word\": \"is\", \"dep_label\": \"auxpass\", \"pos\": \"VBZ\", \"lemma\": \"be\", \"word_idx\": \"28\", \"dep_parent\": \"30\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27404\", \"word\": \"absence\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"absence\", \"word_idx\": \"32\", \"dep_parent\": \"30\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27397\", \"word\": \"by\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"by\", \"word_idx\": \"30\", \"dep_parent\": \"33\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27400\", \"word\": \"the\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"the\", \"word_idx\": \"31\", \"dep_parent\": \"33\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27417\", \"word\": \"MMC\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"mmc\", \"word_idx\": \"35\", \"dep_parent\": \"33\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27412\", \"word\": \"of\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"of\", \"word_idx\": \"33\", \"dep_parent\": \"36\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27415\", \"word\": \"a\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"a\", \"word_idx\": \"34\", \"dep_parent\": \"36\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"27433\", \"word\": \"stage\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"stage\", \"word_idx\": \"39\", \"dep_parent\": \"33\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27421\", \"word\": \"at\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"at\", \"word_idx\": \"36\", \"dep_parent\": \"40\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27424\", \"word\": \"an\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"a\", \"word_idx\": \"37\", \"dep_parent\": \"40\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27427\", \"word\": \"early\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"early\", \"word_idx\": \"38\", \"dep_parent\": \"40\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27448\", \"word\": \"development\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"development\", \"word_idx\": \"42\", \"dep_parent\": \"40\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27439\", \"word\": \"of\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"of\", \"word_idx\": \"40\", \"dep_parent\": \"43\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27442\", \"word\": \"ovule\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"ovule\", \"word_idx\": \"41\", \"dep_parent\": \"43\"}, \"children\": []}]}]}]}]}, {\"attrib\": {\"token_idx\": \"27459\", \"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"43\", \"dep_parent\": \"13\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27466\", \"word\": \"preventing\", \"dep_label\": \"xcomp\", \"pos\": \"VBG\", \"lemma\": \"prevent\", \"word_idx\": \"45\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27461\", \"word\": \"thus\", \"dep_label\": \"advmod\", \"pos\": \"RB\", \"lemma\": \"thus\", \"word_idx\": \"44\", \"dep_parent\": \"46\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27488\", \"word\": \"formation\", \"dep_label\": \"dobj\", \"pos\": \"NN\", \"lemma\": \"formation\", \"word_idx\": \"48\", \"dep_parent\": \"46\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27477\", \"word\": \"embryo\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"embryo\", \"word_idx\": \"46\", \"dep_parent\": \"49\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27484\", \"word\": \"sac\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"sac\", \"word_idx\": \"47\", \"dep_parent\": \"49\"}, \"children\": []}]}]}, {\"attrib\": {\"token_idx\": \"27497\", \"word\": \".\", \"dep_label\": \"punct\", \"pos\": \".\", \"lemma\": \".\", \"word_idx\": \"49\", \"dep_parent\": \"13\"}, \"children\": []}]};\n",
       "var highlightIdxs = [[24], [31, 32, 33, 34, 35]];\n",
       "\n",
       "// Highlight words / nodes\n",
       "var COLORS = [\"#ff5c33\", \"#ffcc00\", \"#33cc33\", \"#3399ff\"];\n",
       "function highlightWords() {\n",
       "  for (var i=0; i < highlightIdxs.length; i++) {\n",
       "    var c = COLORS[i];\n",
       "    var idxs = highlightIdxs[i];\n",
       "    for (var j=0; j < idxs.length; j++) {\n",
       "      d3.selectAll(\".word-\"+chartId+\"-\"+idxs[j]).style(\"stroke\", c).style(\"background\", c);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "// Constants\n",
       "var margin = {top: 20, right: 20, bottom: 20, left: 20},\n",
       "width = 800 - margin.left - margin.right,\n",
       "height = 350 - margin.top - margin.bottom,\n",
       "R = 5;\n",
       "\n",
       "// Create the d3 tree object\n",
       "var tree = d3.layout.tree()\n",
       "  .size([width, height]);\n",
       "\n",
       "// Create the svg canvas\n",
       "var svg = d3.select(\"#tree-chart-\" + chartId)\n",
       "  .append(\"svg\")\n",
       "  .attr(\"width\", width + margin.left + margin.right)\n",
       "  .attr(\"height\", height + margin.top + margin.bottom)\n",
       "  .append(\"g\")\n",
       "  .attr(\"transform\", \"translate(\" + margin.left + \",\" + margin.top + \")\");\n",
       "\n",
       "function renderTree() {\n",
       "  var nodes = tree.nodes(root),\n",
       "  edges = tree.links(nodes);\n",
       "\n",
       "  // Place the nodes\n",
       "  var nodeGroups = svg.selectAll(\"g.node\")\n",
       "    .data(nodes)\n",
       "    .enter().append(\"g\")\n",
       "    .attr(\"class\", \"node\")\n",
       "    .attr(\"transform\", function(d) { return \"translate(\" + d.x + \",\" + d.y + \")\"; });\n",
       "       \n",
       "  // Append circles\n",
       "  nodeGroups.append(\"circle\")\n",
       "    //.on(\"click\", function() {\n",
       "    //  d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"r\", R)\n",
       "    .attr(\"class\", function(d) { return \"word-\"+chartId+\"-\"+d.attrib.word_idx; });\n",
       "     \n",
       "  // Append the actual word\n",
       "  nodeGroups.append(\"text\")\n",
       "    .text(function(d) { return d.attrib.word; })\n",
       "    .attr(\"text-anchor\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? \"start\" : \"middle\"; })\n",
       "    .attr(\"dx\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? R + 3 : 0; })\n",
       "    .attr(\"dy\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? 0 : 3*R + 3; });\n",
       "\n",
       "  // Place the edges\n",
       "  var edgePaths = svg.selectAll(\"path\")\n",
       "    .data(edges)\n",
       "    .enter().append(\"path\")\n",
       "    .attr(\"class\", \"edge\")\n",
       "    .on(\"click\", function() {\n",
       "      d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"d\", d3.svg.diagonal());\n",
       "}\n",
       "\n",
       "renderTree();\n",
       "highlightWords();\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[24] [40, 41, 42] At the fully developed ovule stage the _ spl/nzz _ mutant phenotype resembles that of _ ashh2 _ , but in contrast to _ ashh2 , spl/nzz _ is characterized by the absence of a MMC at an early stage of ovule development , thus preventing embryo sac formation .\n",
      "At the fully developed ovule stage the _ spl/nzz _ mutant phenotype resembles that of _ ashh2 _ , but in contrast to _ {{GeneName}} , spl/nzz _ is characterized by the absence of a MMC at an early stage {{PhenoName}} , thus preventing embryo sac formation .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".node {\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".node circle {\n",
       "  fill: #fff;\n",
       "  stroke: steelblue;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "\n",
       ".node text {\n",
       "  font: 12px sans-serif;\n",
       "}\n",
       "\n",
       ".edge {\n",
       "  fill: none;\n",
       "  stroke: #ccc;\n",
       "  stroke-width: 2px;\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".highlight {\n",
       "  stroke: red;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<!--Provide the canvas id (twice) and the words via python string formatting here--!>\n",
       "<div id=\"tree-chart-5982185982202176091\"></div>\n",
       "<div id=\"raw-seq-5982185982202176091\">\n",
       "<span class=\"word-5982185982202176091-0\">At</span> <span class=\"word-5982185982202176091-1\">the</span> <span class=\"word-5982185982202176091-2\">fully</span> <span class=\"word-5982185982202176091-3\">developed</span> <span class=\"word-5982185982202176091-4\">ovule</span> <span class=\"word-5982185982202176091-5\">stage</span> <span class=\"word-5982185982202176091-6\">the</span> <span class=\"word-5982185982202176091-7\">_</span> <span class=\"word-5982185982202176091-8\">spl/nzz</span> <span class=\"word-5982185982202176091-9\">_</span> <span class=\"word-5982185982202176091-10\">mutant</span> <span class=\"word-5982185982202176091-11\">phenotype</span> <span class=\"word-5982185982202176091-12\">resembles</span> <span class=\"word-5982185982202176091-13\">that</span> <span class=\"word-5982185982202176091-14\">of</span> <span class=\"word-5982185982202176091-15\">_</span> <span class=\"word-5982185982202176091-16\">ashh2</span> <span class=\"word-5982185982202176091-17\">_</span> <span class=\"word-5982185982202176091-18\">,</span> <span class=\"word-5982185982202176091-19\">but</span> <span class=\"word-5982185982202176091-20\">in</span> <span class=\"word-5982185982202176091-21\">contrast</span> <span class=\"word-5982185982202176091-22\">to</span> <span class=\"word-5982185982202176091-23\">_</span> <span class=\"word-5982185982202176091-24\">ashh2</span> <span class=\"word-5982185982202176091-25\">,</span> <span class=\"word-5982185982202176091-26\">spl/nzz</span> <span class=\"word-5982185982202176091-27\">_</span> <span class=\"word-5982185982202176091-28\">is</span> <span class=\"word-5982185982202176091-29\">characterized</span> <span class=\"word-5982185982202176091-30\">by</span> <span class=\"word-5982185982202176091-31\">the</span> <span class=\"word-5982185982202176091-32\">absence</span> <span class=\"word-5982185982202176091-33\">of</span> <span class=\"word-5982185982202176091-34\">a</span> <span class=\"word-5982185982202176091-35\">MMC</span> <span class=\"word-5982185982202176091-36\">at</span> <span class=\"word-5982185982202176091-37\">an</span> <span class=\"word-5982185982202176091-38\">early</span> <span class=\"word-5982185982202176091-39\">stage</span> <span class=\"word-5982185982202176091-40\">of</span> <span class=\"word-5982185982202176091-41\">ovule</span> <span class=\"word-5982185982202176091-42\">development</span> <span class=\"word-5982185982202176091-43\">,</span> <span class=\"word-5982185982202176091-44\">thus</span> <span class=\"word-5982185982202176091-45\">preventing</span> <span class=\"word-5982185982202176091-46\">embryo</span> <span class=\"word-5982185982202176091-47\">sac</span> <span class=\"word-5982185982202176091-48\">formation</span> <span class=\"word-5982185982202176091-49\">.</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "$.getScript(\"http://d3js.org/d3.v3.min.js\", function () {\n",
       "// See http://bl.ocks.org/d3noob/8375092\n",
       "// Three vars need to be provided via python string formatting:\n",
       "var chartId = \"5982185982202176091\";\n",
       "var root = {\"attrib\": {\"token_idx\": \"27317\", \"word\": \"resembles\", \"dep_label\": \"ROOT\", \"pos\": \"VBZ\", \"lemma\": \"resemble\", \"word_idx\": \"12\", \"dep_parent\": \"0\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27280\", \"word\": \"stage\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"stage\", \"word_idx\": \"5\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27251\", \"word\": \"At\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"at\", \"word_idx\": \"0\", \"dep_parent\": \"6\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27254\", \"word\": \"the\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"the\", \"word_idx\": \"1\", \"dep_parent\": \"6\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27264\", \"word\": \"developed\", \"dep_label\": \"amod\", \"pos\": \"VBN\", \"lemma\": \"develop\", \"word_idx\": \"3\", \"dep_parent\": \"6\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27258\", \"word\": \"fully\", \"dep_label\": \"advmod\", \"pos\": \"RB\", \"lemma\": \"fully\", \"word_idx\": \"2\", \"dep_parent\": \"4\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"27274\", \"word\": \"ovule\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"ovule\", \"word_idx\": \"4\", \"dep_parent\": \"6\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"27307\", \"word\": \"phenotype\", \"dep_label\": \"nsubj\", \"pos\": \"NN\", \"lemma\": \"phenotype\", \"word_idx\": \"11\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27286\", \"word\": \"the\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"the\", \"word_idx\": \"6\", \"dep_parent\": \"12\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27290\", \"word\": \"_\", \"dep_label\": \"nummod\", \"pos\": \"CD\", \"lemma\": \"_\", \"word_idx\": \"7\", \"dep_parent\": \"12\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27291\", \"word\": \"spl/nzz\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"spl/nzz\", \"word_idx\": \"8\", \"dep_parent\": \"12\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27298\", \"word\": \"_\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"_\", \"word_idx\": \"9\", \"dep_parent\": \"12\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27300\", \"word\": \"mutant\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"mutant\", \"word_idx\": \"10\", \"dep_parent\": \"12\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"27383\", \"word\": \"characterized\", \"dep_label\": \"ccomp\", \"pos\": \"VBN\", \"lemma\": \"characterize\", \"word_idx\": \"29\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27327\", \"word\": \"that\", \"dep_label\": \"nsubjpass\", \"pos\": \"DT\", \"lemma\": \"that\", \"word_idx\": \"13\", \"dep_parent\": \"30\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27341\", \"word\": \"_\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"_\", \"word_idx\": \"17\", \"dep_parent\": \"14\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27332\", \"word\": \"of\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"of\", \"word_idx\": \"14\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27335\", \"word\": \"_\", \"dep_label\": \"nummod\", \"pos\": \"CD\", \"lemma\": \"_\", \"word_idx\": \"15\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27336\", \"word\": \"ashh2\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"ashh2\", \"word_idx\": \"16\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27342\", \"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"18\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27344\", \"word\": \"but\", \"dep_label\": \"cc\", \"pos\": \"CC\", \"lemma\": \"but\", \"word_idx\": \"19\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27351\", \"word\": \"contrast\", \"dep_label\": \"conj\", \"pos\": \"NN\", \"lemma\": \"contrast\", \"word_idx\": \"21\", \"dep_parent\": \"18\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27348\", \"word\": \"in\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"in\", \"word_idx\": \"20\", \"dep_parent\": \"22\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27364\", \"word\": \"ashh2\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"ashh2\", \"word_idx\": \"24\", \"dep_parent\": \"22\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27360\", \"word\": \"to\", \"dep_label\": \"case\", \"pos\": \"TO\", \"lemma\": \"to\", \"word_idx\": \"22\", \"dep_parent\": \"25\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27363\", \"word\": \"_\", \"dep_label\": \"amod\", \"pos\": \"VB\", \"lemma\": \"_\", \"word_idx\": \"23\", \"dep_parent\": \"25\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27369\", \"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"25\", \"dep_parent\": \"25\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27378\", \"word\": \"_\", \"dep_label\": \"appos\", \"pos\": \"NN\", \"lemma\": \"_\", \"word_idx\": \"27\", \"dep_parent\": \"25\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27371\", \"word\": \"spl/nzz\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"spl/nzz\", \"word_idx\": \"26\", \"dep_parent\": \"28\"}, \"children\": []}]}]}]}]}]}, {\"attrib\": {\"token_idx\": \"27380\", \"word\": \"is\", \"dep_label\": \"auxpass\", \"pos\": \"VBZ\", \"lemma\": \"be\", \"word_idx\": \"28\", \"dep_parent\": \"30\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27404\", \"word\": \"absence\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"absence\", \"word_idx\": \"32\", \"dep_parent\": \"30\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27397\", \"word\": \"by\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"by\", \"word_idx\": \"30\", \"dep_parent\": \"33\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27400\", \"word\": \"the\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"the\", \"word_idx\": \"31\", \"dep_parent\": \"33\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27417\", \"word\": \"MMC\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"mmc\", \"word_idx\": \"35\", \"dep_parent\": \"33\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27412\", \"word\": \"of\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"of\", \"word_idx\": \"33\", \"dep_parent\": \"36\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27415\", \"word\": \"a\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"a\", \"word_idx\": \"34\", \"dep_parent\": \"36\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"27433\", \"word\": \"stage\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"stage\", \"word_idx\": \"39\", \"dep_parent\": \"33\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27421\", \"word\": \"at\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"at\", \"word_idx\": \"36\", \"dep_parent\": \"40\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27424\", \"word\": \"an\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"a\", \"word_idx\": \"37\", \"dep_parent\": \"40\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27427\", \"word\": \"early\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"early\", \"word_idx\": \"38\", \"dep_parent\": \"40\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27448\", \"word\": \"development\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"development\", \"word_idx\": \"42\", \"dep_parent\": \"40\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27439\", \"word\": \"of\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"of\", \"word_idx\": \"40\", \"dep_parent\": \"43\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27442\", \"word\": \"ovule\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"ovule\", \"word_idx\": \"41\", \"dep_parent\": \"43\"}, \"children\": []}]}]}]}]}, {\"attrib\": {\"token_idx\": \"27459\", \"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"43\", \"dep_parent\": \"13\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27466\", \"word\": \"preventing\", \"dep_label\": \"xcomp\", \"pos\": \"VBG\", \"lemma\": \"prevent\", \"word_idx\": \"45\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27461\", \"word\": \"thus\", \"dep_label\": \"advmod\", \"pos\": \"RB\", \"lemma\": \"thus\", \"word_idx\": \"44\", \"dep_parent\": \"46\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27488\", \"word\": \"formation\", \"dep_label\": \"dobj\", \"pos\": \"NN\", \"lemma\": \"formation\", \"word_idx\": \"48\", \"dep_parent\": \"46\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27477\", \"word\": \"embryo\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"embryo\", \"word_idx\": \"46\", \"dep_parent\": \"49\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27484\", \"word\": \"sac\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"sac\", \"word_idx\": \"47\", \"dep_parent\": \"49\"}, \"children\": []}]}]}, {\"attrib\": {\"token_idx\": \"27497\", \"word\": \".\", \"dep_label\": \"punct\", \"pos\": \".\", \"lemma\": \".\", \"word_idx\": \"49\", \"dep_parent\": \"13\"}, \"children\": []}]};\n",
       "var highlightIdxs = [[24], [40, 41, 42]];\n",
       "\n",
       "// Highlight words / nodes\n",
       "var COLORS = [\"#ff5c33\", \"#ffcc00\", \"#33cc33\", \"#3399ff\"];\n",
       "function highlightWords() {\n",
       "  for (var i=0; i < highlightIdxs.length; i++) {\n",
       "    var c = COLORS[i];\n",
       "    var idxs = highlightIdxs[i];\n",
       "    for (var j=0; j < idxs.length; j++) {\n",
       "      d3.selectAll(\".word-\"+chartId+\"-\"+idxs[j]).style(\"stroke\", c).style(\"background\", c);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "// Constants\n",
       "var margin = {top: 20, right: 20, bottom: 20, left: 20},\n",
       "width = 800 - margin.left - margin.right,\n",
       "height = 350 - margin.top - margin.bottom,\n",
       "R = 5;\n",
       "\n",
       "// Create the d3 tree object\n",
       "var tree = d3.layout.tree()\n",
       "  .size([width, height]);\n",
       "\n",
       "// Create the svg canvas\n",
       "var svg = d3.select(\"#tree-chart-\" + chartId)\n",
       "  .append(\"svg\")\n",
       "  .attr(\"width\", width + margin.left + margin.right)\n",
       "  .attr(\"height\", height + margin.top + margin.bottom)\n",
       "  .append(\"g\")\n",
       "  .attr(\"transform\", \"translate(\" + margin.left + \",\" + margin.top + \")\");\n",
       "\n",
       "function renderTree() {\n",
       "  var nodes = tree.nodes(root),\n",
       "  edges = tree.links(nodes);\n",
       "\n",
       "  // Place the nodes\n",
       "  var nodeGroups = svg.selectAll(\"g.node\")\n",
       "    .data(nodes)\n",
       "    .enter().append(\"g\")\n",
       "    .attr(\"class\", \"node\")\n",
       "    .attr(\"transform\", function(d) { return \"translate(\" + d.x + \",\" + d.y + \")\"; });\n",
       "       \n",
       "  // Append circles\n",
       "  nodeGroups.append(\"circle\")\n",
       "    //.on(\"click\", function() {\n",
       "    //  d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"r\", R)\n",
       "    .attr(\"class\", function(d) { return \"word-\"+chartId+\"-\"+d.attrib.word_idx; });\n",
       "     \n",
       "  // Append the actual word\n",
       "  nodeGroups.append(\"text\")\n",
       "    .text(function(d) { return d.attrib.word; })\n",
       "    .attr(\"text-anchor\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? \"start\" : \"middle\"; })\n",
       "    .attr(\"dx\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? R + 3 : 0; })\n",
       "    .attr(\"dy\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? 0 : 3*R + 3; });\n",
       "\n",
       "  // Place the edges\n",
       "  var edgePaths = svg.selectAll(\"path\")\n",
       "    .data(edges)\n",
       "    .enter().append(\"path\")\n",
       "    .attr(\"class\", \"edge\")\n",
       "    .on(\"click\", function() {\n",
       "      d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"d\", d3.svg.diagonal());\n",
       "}\n",
       "\n",
       "renderTree();\n",
       "highlightWords();\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[24] [46, 47, 48] At the fully developed ovule stage the _ spl/nzz _ mutant phenotype resembles that of _ ashh2 _ , but in contrast to _ ashh2 , spl/nzz _ is characterized by the absence of a MMC at an early stage of ovule development , thus preventing embryo sac formation .\n",
      "At the fully developed ovule stage the _ spl/nzz _ mutant phenotype resembles that of _ ashh2 _ , but in contrast to _ {{GeneName}} , spl/nzz _ is characterized by the absence of a MMC at an early stage of ovule development , thus preventing {{PhenoName}} .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".node {\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".node circle {\n",
       "  fill: #fff;\n",
       "  stroke: steelblue;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "\n",
       ".node text {\n",
       "  font: 12px sans-serif;\n",
       "}\n",
       "\n",
       ".edge {\n",
       "  fill: none;\n",
       "  stroke: #ccc;\n",
       "  stroke-width: 2px;\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".highlight {\n",
       "  stroke: red;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<!--Provide the canvas id (twice) and the words via python string formatting here--!>\n",
       "<div id=\"tree-chart-5982185982202176091\"></div>\n",
       "<div id=\"raw-seq-5982185982202176091\">\n",
       "<span class=\"word-5982185982202176091-0\">At</span> <span class=\"word-5982185982202176091-1\">the</span> <span class=\"word-5982185982202176091-2\">fully</span> <span class=\"word-5982185982202176091-3\">developed</span> <span class=\"word-5982185982202176091-4\">ovule</span> <span class=\"word-5982185982202176091-5\">stage</span> <span class=\"word-5982185982202176091-6\">the</span> <span class=\"word-5982185982202176091-7\">_</span> <span class=\"word-5982185982202176091-8\">spl/nzz</span> <span class=\"word-5982185982202176091-9\">_</span> <span class=\"word-5982185982202176091-10\">mutant</span> <span class=\"word-5982185982202176091-11\">phenotype</span> <span class=\"word-5982185982202176091-12\">resembles</span> <span class=\"word-5982185982202176091-13\">that</span> <span class=\"word-5982185982202176091-14\">of</span> <span class=\"word-5982185982202176091-15\">_</span> <span class=\"word-5982185982202176091-16\">ashh2</span> <span class=\"word-5982185982202176091-17\">_</span> <span class=\"word-5982185982202176091-18\">,</span> <span class=\"word-5982185982202176091-19\">but</span> <span class=\"word-5982185982202176091-20\">in</span> <span class=\"word-5982185982202176091-21\">contrast</span> <span class=\"word-5982185982202176091-22\">to</span> <span class=\"word-5982185982202176091-23\">_</span> <span class=\"word-5982185982202176091-24\">ashh2</span> <span class=\"word-5982185982202176091-25\">,</span> <span class=\"word-5982185982202176091-26\">spl/nzz</span> <span class=\"word-5982185982202176091-27\">_</span> <span class=\"word-5982185982202176091-28\">is</span> <span class=\"word-5982185982202176091-29\">characterized</span> <span class=\"word-5982185982202176091-30\">by</span> <span class=\"word-5982185982202176091-31\">the</span> <span class=\"word-5982185982202176091-32\">absence</span> <span class=\"word-5982185982202176091-33\">of</span> <span class=\"word-5982185982202176091-34\">a</span> <span class=\"word-5982185982202176091-35\">MMC</span> <span class=\"word-5982185982202176091-36\">at</span> <span class=\"word-5982185982202176091-37\">an</span> <span class=\"word-5982185982202176091-38\">early</span> <span class=\"word-5982185982202176091-39\">stage</span> <span class=\"word-5982185982202176091-40\">of</span> <span class=\"word-5982185982202176091-41\">ovule</span> <span class=\"word-5982185982202176091-42\">development</span> <span class=\"word-5982185982202176091-43\">,</span> <span class=\"word-5982185982202176091-44\">thus</span> <span class=\"word-5982185982202176091-45\">preventing</span> <span class=\"word-5982185982202176091-46\">embryo</span> <span class=\"word-5982185982202176091-47\">sac</span> <span class=\"word-5982185982202176091-48\">formation</span> <span class=\"word-5982185982202176091-49\">.</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "$.getScript(\"http://d3js.org/d3.v3.min.js\", function () {\n",
       "// See http://bl.ocks.org/d3noob/8375092\n",
       "// Three vars need to be provided via python string formatting:\n",
       "var chartId = \"5982185982202176091\";\n",
       "var root = {\"attrib\": {\"token_idx\": \"27317\", \"word\": \"resembles\", \"dep_label\": \"ROOT\", \"pos\": \"VBZ\", \"lemma\": \"resemble\", \"word_idx\": \"12\", \"dep_parent\": \"0\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27280\", \"word\": \"stage\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"stage\", \"word_idx\": \"5\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27251\", \"word\": \"At\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"at\", \"word_idx\": \"0\", \"dep_parent\": \"6\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27254\", \"word\": \"the\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"the\", \"word_idx\": \"1\", \"dep_parent\": \"6\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27264\", \"word\": \"developed\", \"dep_label\": \"amod\", \"pos\": \"VBN\", \"lemma\": \"develop\", \"word_idx\": \"3\", \"dep_parent\": \"6\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27258\", \"word\": \"fully\", \"dep_label\": \"advmod\", \"pos\": \"RB\", \"lemma\": \"fully\", \"word_idx\": \"2\", \"dep_parent\": \"4\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"27274\", \"word\": \"ovule\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"ovule\", \"word_idx\": \"4\", \"dep_parent\": \"6\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"27307\", \"word\": \"phenotype\", \"dep_label\": \"nsubj\", \"pos\": \"NN\", \"lemma\": \"phenotype\", \"word_idx\": \"11\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27286\", \"word\": \"the\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"the\", \"word_idx\": \"6\", \"dep_parent\": \"12\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27290\", \"word\": \"_\", \"dep_label\": \"nummod\", \"pos\": \"CD\", \"lemma\": \"_\", \"word_idx\": \"7\", \"dep_parent\": \"12\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27291\", \"word\": \"spl/nzz\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"spl/nzz\", \"word_idx\": \"8\", \"dep_parent\": \"12\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27298\", \"word\": \"_\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"_\", \"word_idx\": \"9\", \"dep_parent\": \"12\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27300\", \"word\": \"mutant\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"mutant\", \"word_idx\": \"10\", \"dep_parent\": \"12\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"27383\", \"word\": \"characterized\", \"dep_label\": \"ccomp\", \"pos\": \"VBN\", \"lemma\": \"characterize\", \"word_idx\": \"29\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27327\", \"word\": \"that\", \"dep_label\": \"nsubjpass\", \"pos\": \"DT\", \"lemma\": \"that\", \"word_idx\": \"13\", \"dep_parent\": \"30\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27341\", \"word\": \"_\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"_\", \"word_idx\": \"17\", \"dep_parent\": \"14\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27332\", \"word\": \"of\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"of\", \"word_idx\": \"14\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27335\", \"word\": \"_\", \"dep_label\": \"nummod\", \"pos\": \"CD\", \"lemma\": \"_\", \"word_idx\": \"15\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27336\", \"word\": \"ashh2\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"ashh2\", \"word_idx\": \"16\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27342\", \"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"18\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27344\", \"word\": \"but\", \"dep_label\": \"cc\", \"pos\": \"CC\", \"lemma\": \"but\", \"word_idx\": \"19\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27351\", \"word\": \"contrast\", \"dep_label\": \"conj\", \"pos\": \"NN\", \"lemma\": \"contrast\", \"word_idx\": \"21\", \"dep_parent\": \"18\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27348\", \"word\": \"in\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"in\", \"word_idx\": \"20\", \"dep_parent\": \"22\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27364\", \"word\": \"ashh2\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"ashh2\", \"word_idx\": \"24\", \"dep_parent\": \"22\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27360\", \"word\": \"to\", \"dep_label\": \"case\", \"pos\": \"TO\", \"lemma\": \"to\", \"word_idx\": \"22\", \"dep_parent\": \"25\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27363\", \"word\": \"_\", \"dep_label\": \"amod\", \"pos\": \"VB\", \"lemma\": \"_\", \"word_idx\": \"23\", \"dep_parent\": \"25\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27369\", \"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"25\", \"dep_parent\": \"25\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27378\", \"word\": \"_\", \"dep_label\": \"appos\", \"pos\": \"NN\", \"lemma\": \"_\", \"word_idx\": \"27\", \"dep_parent\": \"25\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27371\", \"word\": \"spl/nzz\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"spl/nzz\", \"word_idx\": \"26\", \"dep_parent\": \"28\"}, \"children\": []}]}]}]}]}]}, {\"attrib\": {\"token_idx\": \"27380\", \"word\": \"is\", \"dep_label\": \"auxpass\", \"pos\": \"VBZ\", \"lemma\": \"be\", \"word_idx\": \"28\", \"dep_parent\": \"30\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27404\", \"word\": \"absence\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"absence\", \"word_idx\": \"32\", \"dep_parent\": \"30\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27397\", \"word\": \"by\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"by\", \"word_idx\": \"30\", \"dep_parent\": \"33\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27400\", \"word\": \"the\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"the\", \"word_idx\": \"31\", \"dep_parent\": \"33\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27417\", \"word\": \"MMC\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"mmc\", \"word_idx\": \"35\", \"dep_parent\": \"33\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27412\", \"word\": \"of\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"of\", \"word_idx\": \"33\", \"dep_parent\": \"36\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27415\", \"word\": \"a\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"a\", \"word_idx\": \"34\", \"dep_parent\": \"36\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"27433\", \"word\": \"stage\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"stage\", \"word_idx\": \"39\", \"dep_parent\": \"33\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27421\", \"word\": \"at\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"at\", \"word_idx\": \"36\", \"dep_parent\": \"40\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27424\", \"word\": \"an\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"a\", \"word_idx\": \"37\", \"dep_parent\": \"40\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27427\", \"word\": \"early\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"early\", \"word_idx\": \"38\", \"dep_parent\": \"40\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27448\", \"word\": \"development\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"development\", \"word_idx\": \"42\", \"dep_parent\": \"40\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27439\", \"word\": \"of\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"of\", \"word_idx\": \"40\", \"dep_parent\": \"43\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27442\", \"word\": \"ovule\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"ovule\", \"word_idx\": \"41\", \"dep_parent\": \"43\"}, \"children\": []}]}]}]}]}, {\"attrib\": {\"token_idx\": \"27459\", \"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"43\", \"dep_parent\": \"13\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27466\", \"word\": \"preventing\", \"dep_label\": \"xcomp\", \"pos\": \"VBG\", \"lemma\": \"prevent\", \"word_idx\": \"45\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27461\", \"word\": \"thus\", \"dep_label\": \"advmod\", \"pos\": \"RB\", \"lemma\": \"thus\", \"word_idx\": \"44\", \"dep_parent\": \"46\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27488\", \"word\": \"formation\", \"dep_label\": \"dobj\", \"pos\": \"NN\", \"lemma\": \"formation\", \"word_idx\": \"48\", \"dep_parent\": \"46\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27477\", \"word\": \"embryo\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"embryo\", \"word_idx\": \"46\", \"dep_parent\": \"49\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27484\", \"word\": \"sac\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"sac\", \"word_idx\": \"47\", \"dep_parent\": \"49\"}, \"children\": []}]}]}, {\"attrib\": {\"token_idx\": \"27497\", \"word\": \".\", \"dep_label\": \"punct\", \"pos\": \".\", \"lemma\": \".\", \"word_idx\": \"49\", \"dep_parent\": \"13\"}, \"children\": []}]};\n",
       "var highlightIdxs = [[24], [46, 47, 48]];\n",
       "\n",
       "// Highlight words / nodes\n",
       "var COLORS = [\"#ff5c33\", \"#ffcc00\", \"#33cc33\", \"#3399ff\"];\n",
       "function highlightWords() {\n",
       "  for (var i=0; i < highlightIdxs.length; i++) {\n",
       "    var c = COLORS[i];\n",
       "    var idxs = highlightIdxs[i];\n",
       "    for (var j=0; j < idxs.length; j++) {\n",
       "      d3.selectAll(\".word-\"+chartId+\"-\"+idxs[j]).style(\"stroke\", c).style(\"background\", c);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "// Constants\n",
       "var margin = {top: 20, right: 20, bottom: 20, left: 20},\n",
       "width = 800 - margin.left - margin.right,\n",
       "height = 350 - margin.top - margin.bottom,\n",
       "R = 5;\n",
       "\n",
       "// Create the d3 tree object\n",
       "var tree = d3.layout.tree()\n",
       "  .size([width, height]);\n",
       "\n",
       "// Create the svg canvas\n",
       "var svg = d3.select(\"#tree-chart-\" + chartId)\n",
       "  .append(\"svg\")\n",
       "  .attr(\"width\", width + margin.left + margin.right)\n",
       "  .attr(\"height\", height + margin.top + margin.bottom)\n",
       "  .append(\"g\")\n",
       "  .attr(\"transform\", \"translate(\" + margin.left + \",\" + margin.top + \")\");\n",
       "\n",
       "function renderTree() {\n",
       "  var nodes = tree.nodes(root),\n",
       "  edges = tree.links(nodes);\n",
       "\n",
       "  // Place the nodes\n",
       "  var nodeGroups = svg.selectAll(\"g.node\")\n",
       "    .data(nodes)\n",
       "    .enter().append(\"g\")\n",
       "    .attr(\"class\", \"node\")\n",
       "    .attr(\"transform\", function(d) { return \"translate(\" + d.x + \",\" + d.y + \")\"; });\n",
       "       \n",
       "  // Append circles\n",
       "  nodeGroups.append(\"circle\")\n",
       "    //.on(\"click\", function() {\n",
       "    //  d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"r\", R)\n",
       "    .attr(\"class\", function(d) { return \"word-\"+chartId+\"-\"+d.attrib.word_idx; });\n",
       "     \n",
       "  // Append the actual word\n",
       "  nodeGroups.append(\"text\")\n",
       "    .text(function(d) { return d.attrib.word; })\n",
       "    .attr(\"text-anchor\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? \"start\" : \"middle\"; })\n",
       "    .attr(\"dx\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? R + 3 : 0; })\n",
       "    .attr(\"dy\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? 0 : 3*R + 3; });\n",
       "\n",
       "  // Place the edges\n",
       "  var edgePaths = svg.selectAll(\"path\")\n",
       "    .data(edges)\n",
       "    .enter().append(\"path\")\n",
       "    .attr(\"class\", \"edge\")\n",
       "    .on(\"click\", function() {\n",
       "      d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"d\", d3.svg.diagonal());\n",
       "}\n",
       "\n",
       "renderTree();\n",
       "highlightWords();\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#Brief code to see all the candidates from a certain sentence\n",
    "#Copy and paste the ext_id from the 'show details' button from a certain sentence in mindtagger above to see all the different candidates from this sentence\n",
    "test_ext_id=393\n",
    "count=0\n",
    "for i in range(len(R)):\n",
    "    if R[i].sent_id == R[test_ext_id].sent_id and R[i].doc_id == R[test_ext_id].doc_id:\n",
    "        count +=1\n",
    "        print R[i].e1_idxs, R[i].e2_idxs, ' '.join(R[i].words)\n",
    "        print R[i].tagged_sent\n",
    "#         if count <=1:\n",
    "        print R[i].render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chebi_ontology\n"
     ]
    }
   ],
   "source": [
    "#Brief code to see from which phenotype dictionary a word is from\n",
    "str_to_test='result'\n",
    "\n",
    "list_phenos_dict = [phenos_deepdive,phenos_arabidopsis,phenos_worm_variants,phenos_all_eq_dict,phenos_manual,po_ontology,chebi_ontology,go_ontology,pato_ontology,dict_linkwords]\n",
    "list_phenos_dict_names = ['phenos_deepdive','phenos_arabidopsis','phenos_worm_variants','phenos_all_eq_dict','phenos_manual','po_ontology','chebi_ontology','go_ontology','pato_ontology','dict_linkwords']\n",
    "for i, dict_var in enumerate(list_phenos_dict):\n",
    "    if str_to_test in [x.lower() for x in dict_var]:\n",
    "        print list_phenos_dict_names[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LFs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-2e9ab765b41d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_ext_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m212\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mLFs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"no labeling functions yet\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LFs' is not defined"
     ]
    }
   ],
   "source": [
    "#Brief code to see the labeling functions for a certain candidate\n",
    "test_ext_id=212\n",
    "\n",
    "if LFs is None:\n",
    "    print \"no labeling functions yet\"\n",
    "else:\n",
    "    for lf in LFs:\n",
    "        value_lf = lf(DDL.C[test_ext_id])\n",
    "        if value_lf != 0:\n",
    "            print lf, value_lf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing labeling functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use data programming to learn a logistic regression model which will predict the probability of a candidate entity being a true gene mention. Since our training data is not manually labeled, we'll generate many (potentially noisy) labels as a surrogate for precise, manual labels. Feature extraction and model learning are very simple in ddlite. Writing labeling functions is where the real artistry comes in. One of ddlite's goals is to enable rapid prototyping, debugging, and experimenting with labeling functions. These can be used either to create a simple standalone app, or to plug into DeepDive. Labeling functions, or LFs, are functions that take an Candidate object. They must return 1 (for a positive label), 0 (for abstaining), or -1 (for a negative example). For now, we'll write a few simple LFs to get started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count=0\n",
    "for relation in R:\n",
    "    if 'loss' in relation.words:\n",
    "        count+=1\n",
    "        if count <10:\n",
    "            relation.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Here, idx_mention refers to 0 or 1, whether we consider the gene or phenotype\n",
    "def post_window(r, idx_mention, key, n=3):\n",
    "    s = list(r.all_idxs[idx_mention])\n",
    "    b = len(r.lemmas) - np.max(s)\n",
    "    s.extend([np.max(s) + i for i in range(1, min(b,n+1))])\n",
    "    return key in [r.lemmas[i] for i in s]\n",
    "def pre_window (r, idx_mention, key, n=3):\n",
    "    s = list(r.all_idxs[idx_mention])\n",
    "    b = np.min(s)\n",
    "    s.extend([b - i for i in range(1, min(b,n+1))])\n",
    "    return key in [r.lemmas[i] for i in s]\n",
    "def stopper(r, idx_mention, stop):\n",
    "    return stop in [r.lemmas[i] for i in r.all_idxs[idx_mention]]\n",
    "\n",
    "#If the word mutation is before gene:\n",
    "def LF_mutation_gene_t(r):\n",
    "    if 'mutation' in [r.lemmas[r.dep_parents[i]-1] for i in r.all_idxs[0]]:\n",
    "        return 1\n",
    "    else:\n",
    "        if 'mutant' in [r.lemmas[r.dep_parents[i]-1] for i in r.all_idxs[0]]:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "#If the word mutation is before pheno:\n",
    "def LF_mutation_pheno_t(r):\n",
    "    if 'mutation' in [r.lemmas[r.dep_parents[i]-1] for i in r.all_idxs[1]]:\n",
    "        return 1\n",
    "    else:\n",
    "        if 'mutant' in [r.lemmas[r.dep_parents[i]-1] for i in r.all_idxs[1]]:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "#If phenotype just before gene, certainly wrong\n",
    "def LF_pheno_before_gene_f(r):\n",
    "    res=False\n",
    "    for i in r.all_idxs[1]:\n",
    "        if pre_window(r, 0, r.words[i], n=1):\n",
    "            res=True\n",
    "    if res:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "#If phenotype is only a verb, likely to be false\n",
    "def LF_pheno_only_verb_f(r):\n",
    "    if len(r.all_idxs[1])==1 and r.poses[r.all_idxs[1][0]][0:2] == 'VB':\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "#if phenotype only one word, likely to be false (except lethal)\n",
    "def LF_pheno_only_one_word_f(r):\n",
    "    if len(r.all_idxs[1])==1 and r.lemmas[r.all_idxs[1][0]] != 'lethal':\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "#if gene and phenotype have words in common, very likely to be false\n",
    "def LF_gene_pheno_words_in_common_f(r):\n",
    "    if len([val for val in r.all_idxs[0] if val in r.all_idxs[1]]) >0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "#if gfp at the end of a gene, likely to be false\n",
    "def LF_gene_ends_in_gfp_f(r):\n",
    "    if len(r.all_idxs[0])==1 and len(r.mention1()[0]) >2 and r.mention1()[0][-3:].lower() == 'gfp':\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "#If double mutant around the gene name, more likely true:\n",
    "def LF_double_mutant_gene_t(r):\n",
    "    if (post_window(r, 0, 'double', 3) and post_window(r, 0, 'mutant', 3)) or (pre_window(r, 0, 'double', 3) and pre_window(r, 0, 'mutant', 3)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "#If mutant around the gene name, more likely true:\n",
    "def LF_mutant_gene_t(r):\n",
    "    if post_window(r, 0, 'mutant', 3) or pre_window(r, 0, 'mutant', 3):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "#'In WT' is generally not a phenotype\n",
    "# Now useless since we remove directly the WT phenotype candidates.\n",
    "# def LF_in_WT_pheno_f(r):\n",
    "#     if len(r.all_idxs[1])==1 and r.words[r.all_idxs[1][0]] == 'WT' and pre_window(r,1, 'in', 1):\n",
    "#         return -1\n",
    "#     else:\n",
    "#         return 0\n",
    "#If the sentence mentions \"loss of [GENE]\n",
    "def LF_loss_of_gene_t(r):\n",
    "    if 'loss' in [r.lemmas[r.dep_parents[i]-1] for i in r.all_idxs[0]]:\n",
    "        return 1\n",
    "    if post_window(r, 0, 'loss', 3) or pre_window(r, 0, 'loss', 3):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0    \n",
    "#if the word 'defect' is around the gene\n",
    "def LF_defect_of_gene_t(r):\n",
    "    if 'defect' in [r.lemmas[r.dep_parents[i]-1] for i in r.all_idxs[0]]:\n",
    "        return 1\n",
    "    if post_window(r, 0, 'defect', 3) or pre_window(r, 0, 'defect', 3):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LFs= [LF_mutation_gene_t, LF_mutation_pheno_t, LF_pheno_before_gene_f, LF_pheno_only_verb_f, LF_pheno_only_one_word_f, LF_gene_pheno_words_in_common_f, LF_gene_ends_in_gfp_f, LF_double_mutant_gene_t, LF_mutant_gene_t, LF_loss_of_gene_t, LF_defect_of_gene_t]\n",
    "DDL.apply_lfs(LFs, clear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### More analysis on the labeling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DDL.print_lf_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "DDL.plot_lf_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DDL.top_conflict_lfs(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DDL.lowest_coverage_lfs(n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DDL.lowest_empirical_accuracy_lfs(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's have a look at the labeled elements:\n",
    "# DDL.get_labeled_ground_truth(gt='resolve', subset=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print DDL.lf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DDL.C[16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (12,4)\n",
    "#Try with bias=True, error currently for some reasons\n",
    "%time DDL.learn_weights(sample=False, alpha=0.5, n_iter=500, bias=True, verbose=True, log=True, mu=1e-6)\n",
    "# %time DDL.learn_weights(sample=False, alpha=0, bias=False, verbose=True, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "DDL.plot_calibration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DDL.lf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterating with labeling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DDL.show_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# DDL.open_mindtagger(width='100%', height=1200)\n",
    "DDL.open_mindtagger(num_sample=200, width='100%', height=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ext_id are available from mindtag, we can write quick functions to extract:\n",
    "#- all candidates in this sentence (from sent_id, match in R)\n",
    "#- all label functions, from label matrix\n",
    "R[1020].render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt with Multi Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we concatenante 2 sentences in a same document, then export all the relations from this new dataset and keep only the candidates that have a \".\" between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function to merge two dependencies path, just a prototype currently, many different possible\n",
    "#In this function, the \".\" between the two sentences is placed as the root and the sentences are attached below\n",
    "def merge_dependency_paths(dep_parent1, dep_parent2):\n",
    "    res_dep_parents = dep_parent1+dep_parent2\n",
    "    idx_root_sent1=-1\n",
    "    for i in range(len(dep_parent1)):\n",
    "        if dep_parent1[i]==0:\n",
    "            idx_root_sent1=i\n",
    "            break\n",
    "    idx_root_sent2=-1\n",
    "    for i in range(len(dep_parent2)):\n",
    "        if dep_parent2[i]==0:\n",
    "            idx_root_sent2=i\n",
    "        res_dep_parents[len(dep_parent1)+i]=dep_parent2[i]+len(dep_parent1)\n",
    "    #Setting the \".\" between the two sentences as the root\n",
    "    res_dep_parents[len(dep_parent1)-1]=0\n",
    "    #Connecting the two previous roots this new root\n",
    "    res_dep_parents[idx_root_sent1]=len(dep_parent1)\n",
    "    res_dep_parents[idx_root_sent2+len(dep_parent1)]=len(dep_parent1)\n",
    "    return res_dep_parents\n",
    "\n",
    "\n",
    "sents_multi = []\n",
    "for idx in range(len(sents)-1):\n",
    "    if sents[idx+1].doc_id == sents[idx].doc_id and sents[idx+1].sent_id == sents[idx].sent_id+1:\n",
    "        parts = defaultdict(list)\n",
    "        parts['words']=(sents[idx].words+sents[idx+1].words)\n",
    "        parts['lemmas']=(sents[idx].lemmas+sents[idx+1].lemmas)\n",
    "        parts['poses']=(sents[idx].poses+sents[idx+1].poses)\n",
    "        parts['token_idxs']=(sents[idx].token_idxs+sents[idx+1].token_idxs)\n",
    "        parts['dep_labels']=(sents[idx].dep_labels+sents[idx+1].dep_labels)\n",
    "        parts['sent_id']=(sents[idx].sent_id)\n",
    "        parts['doc_id']=(sents[idx].doc_id)\n",
    "        parts['text']=(sents[idx].text+' '+ sents[idx+1].text)\n",
    "        parts['dep_parents']=(merge_dependency_paths(sents[idx].dep_parents, sents[idx+1].dep_parents))\n",
    "        res_sent = Sentence(**parts)\n",
    "        sents_multi.append(res_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print sents[0].words + sents[1].words\n",
    "print ' '\n",
    "print sents_multi[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R_multi = Relations(sents_multi, GM, PM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "R_multi[10].render()\n",
    "# R[0].render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Filtering and removing \n",
    "R_multi.num_feats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DDL_multi = DDLiteModel(R_multi)\n",
    "print \"Extracted {} features for each of {} mentions\".format(DDL_multi.num_feats(), DDL_multi.num_candidates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DDL.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DDL.get_gt_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
