{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepDiveLite (DDL) Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, re, cPickle\n",
    "from ddlite import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw input -> Sentences\n",
    "\n",
    "As a first stage we load a set of documents as raw strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = [open('raw/%s' % fn).read() for fn in os.listdir('raw')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we transform these document strings to a _list of lists_ of DDL `Sentence` objects.  We use the `SentenceParser.parse` method to parse the documents, which by default does a variety of NLP pre-processing as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time parsed_docs = parse_docs_multicore(docs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing doc 0...\n",
      "Parsing doc 1...\n",
      "Parsing doc 2...\n",
      "Parsing doc 3...\n",
      "Parsing doc 4...\n",
      "Parsing doc 5...\n",
      "Parsing doc 6...\n",
      "Parsing doc 7...\n",
      "Parsing doc 8...\n",
      "Parsing doc 9...\n",
      "Parsing doc 10...\n",
      "Parsing doc 11...\n",
      "Parsing doc 12...\n",
      "Parsing doc 13...\n",
      "Parsing doc 14...\n",
      "Parsing doc 15...\n",
      "Parsing doc 16...\n",
      "Parsing doc 17...\n",
      "Parsing doc 18...\n",
      "Parsing doc 19...\n",
      "CPU times: user 1.09 s, sys: 481 ms, total: 1.57 s\n",
      "Wall time: 8min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sents = []\n",
    "for i,doc in enumerate(docs[:20]):\n",
    "    print \"Parsing doc %s...\" % i\n",
    "    sents.append(list(parser.parse(doc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 1\n",
      "2 7\n",
      "3 1\n",
      "4 1\n",
      "5 91\n",
      "6 1\n",
      "7 1\n",
      "8 1\n",
      "9 1\n",
      "10 1\n",
      "11 1\n",
      "12 2\n",
      "13 1\n",
      "14 243\n",
      "15 185\n",
      "16 237\n",
      "17 1\n",
      "18 1\n",
      "19 1\n"
     ]
    }
   ],
   "source": [
    "for i,sent in enumerate(sents):\n",
    "    print i, len(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing doc 0...\n",
      "Parsing doc 1...\n",
      "Parsing doc 2...\n",
      "Parsing doc 3...\n",
      "Parsing doc 4...\n",
      "Parsing doc 5...\n",
      "Parsing doc 6...\n",
      "Parsing doc 7...\n",
      "Parsing doc 8...\n",
      "Parsing doc 9...\n",
      "Parsing doc 10...\n",
      "Parsing doc 11...\n",
      "Parsing doc 12...\n",
      "Parsing doc 13...\n",
      "Parsing doc 14...\n",
      "Parsing doc 15...\n",
      "Parsing doc 16...\n",
      "Parsing doc 17...\n",
      "Parsing doc 18...\n",
      "Parsing doc 19...\n",
      "CPU times: user 1.18 s, sys: 497 ms, total: 1.67 s\n",
      "Wall time: 8min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sents = []\n",
    "for i,doc in enumerate(docs[:20]):\n",
    "    print \"Parsing doc %s...\" % i\n",
    "    sents.append(list(parser.parse(doc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.06 s, sys: 200 ms, total: 1.26 s\n",
      "Wall time: 7min 48s\n"
     ]
    }
   ],
   "source": [
    "%time sents = list(parser.parse_docs(docs[:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since parsing / preprocessing (above) is probably the slowest part of the process, we'll save the processed `Sentence` objects to disk as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cPickle.dump(sents, open('saved_sents.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we'll pick a _random_ sentence to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence(words=[u'Although', u'the', u'BMPR-II', u'tail', u'is', u'not', u'involved', u'in', u'BMP', u'signaling', u'via', u'Smad', u'proteins', u'mutations', u'truncating', u'this', u'domain', u'are', u'present', u'in', u'patients', u'with', u'primary', u'pulmonary', u'hypertension', u'PPH'], lemmas=[u'although', u'the', u'bmpr-ii', u'tail', u'is', u'not', u'involv', u'in', u'bmp', u'signal', u'via', u'smad', u'protein', u'mutat', u'truncat', u'thi', u'domain', u'are', u'present', u'in', u'patient', u'with', u'primari', u'pulmonari', u'hypertens', u'pph'], poses=[u'IN', u'DT', u'JJ', u'NN', u'VBZ', u'RB', u'VBN', u'IN', u'NNP', u'NNP', u'IN', u'NNP', u'NNS', u'NNS', u'VBG', u'DT', u'NN', u'VBP', u'JJ', u'IN', u'NNS', u'IN', u'JJ', u'JJ', u'NN', u'NNP'], dep_parents=[7, 4, 4, 7, 7, 7, 19, 10, 10, 7, 13, 13, 10, 19, 14, 17, 15, 19, 0, 21, 19, 25, 25, 25, 21, 25], dep_labels=[u'mark', u'det', u'amod', u'nsubjpass', u'auxpass', u'neg', u'advcl', u'case', u'compound', u'nmod', u'case', u'compound', u'nmod', u'nsubj', u'acl', u'det', u'dobj', u'cop', u'root', u'case', u'nmod', u'case', u'amod', u'amod', u'nmod', u'appos'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = sents[15][4]; sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Extraction\n",
    "\n",
    "First, we load a dictionary of gene and phenotype names- these are the entities that we want to extract relations over:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Schema is: ENSEMBL_ID | NAME | TYPE (refseq, canonical, non-canonical)\n",
    "genes = [line.rstrip().split('\\t')[1] for line in open('dicts/ensembl_genes.tsv')]\n",
    "genes = filter(lambda g : len(g) > 3, genes)\n",
    "\n",
    "# Schema is: HPO_ID | NAME | TYPE (exact, lemma)\n",
    "phenos = [line.rstrip().split('\\t')[1] for line in open('dicts/pheno_terms.tsv')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the type of relation we want to look for.  To do this, we'll define a DDL `Relations` operator, which is built from two `Entity`-type operators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rels = Relations(\n",
    "    DictionaryMatch('G', genes, ignore_case=False), \n",
    "    DictionaryMatch('P', phenos), \n",
    "    [sent])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also render a visualization of the relations / their contexts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".node {\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".node circle {\n",
       "  fill: #fff;\n",
       "  stroke: steelblue;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "\n",
       ".node text {\n",
       "  font: 12px sans-serif;\n",
       "}\n",
       "\n",
       ".edge {\n",
       "  fill: none;\n",
       "  stroke: #ccc;\n",
       "  stroke-width: 2px;\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".highlight {\n",
       "  stroke: red;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<!--Provide the canvas id (twice) and the words via python string formatting here--!>\n",
       "<div id=\"tree-chart-3288496975806822501\"></div>\n",
       "<div id=\"raw-seq-3288496975806822501\">\n",
       "<span class=\"word-3288496975806822501-0\">Although</span> <span class=\"word-3288496975806822501-1\">the</span> <span class=\"word-3288496975806822501-2\">BMPR-II</span> <span class=\"word-3288496975806822501-3\">tail</span> <span class=\"word-3288496975806822501-4\">is</span> <span class=\"word-3288496975806822501-5\">not</span> <span class=\"word-3288496975806822501-6\">involved</span> <span class=\"word-3288496975806822501-7\">in</span> <span class=\"word-3288496975806822501-8\">BMP</span> <span class=\"word-3288496975806822501-9\">signaling</span> <span class=\"word-3288496975806822501-10\">via</span> <span class=\"word-3288496975806822501-11\">Smad</span> <span class=\"word-3288496975806822501-12\">proteins</span> <span class=\"word-3288496975806822501-13\">mutations</span> <span class=\"word-3288496975806822501-14\">truncating</span> <span class=\"word-3288496975806822501-15\">this</span> <span class=\"word-3288496975806822501-16\">domain</span> <span class=\"word-3288496975806822501-17\">are</span> <span class=\"word-3288496975806822501-18\">present</span> <span class=\"word-3288496975806822501-19\">in</span> <span class=\"word-3288496975806822501-20\">patients</span> <span class=\"word-3288496975806822501-21\">with</span> <span class=\"word-3288496975806822501-22\">primary</span> <span class=\"word-3288496975806822501-23\">pulmonary</span> <span class=\"word-3288496975806822501-24\">hypertension</span> <span class=\"word-3288496975806822501-25\">PPH</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "$.getScript(\"http://d3js.org/d3.v3.min.js\", function () {\n",
       "// See http://bl.ocks.org/d3noob/8375092\n",
       "// Three vars need to be provided via python string formatting:\n",
       "var chartId = \"3288496975806822501\";\n",
       "var root = {\"attrib\": {\"word\": \"present\", \"dep_label\": \"root\", \"pos\": \"JJ\", \"lemma\": \"present\", \"word_idx\": \"18\", \"dep_parent\": \"0\"}, \"children\": [{\"attrib\": {\"word\": \"involved\", \"dep_label\": \"advcl\", \"pos\": \"VBN\", \"lemma\": \"involv\", \"word_idx\": \"6\", \"dep_parent\": \"19\"}, \"children\": [{\"attrib\": {\"word\": \"Although\", \"dep_label\": \"mark\", \"pos\": \"IN\", \"lemma\": \"although\", \"word_idx\": \"0\", \"dep_parent\": \"7\"}, \"children\": []}, {\"attrib\": {\"word\": \"tail\", \"dep_label\": \"nsubjpass\", \"pos\": \"NN\", \"lemma\": \"tail\", \"word_idx\": \"3\", \"dep_parent\": \"7\"}, \"children\": [{\"attrib\": {\"word\": \"the\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"the\", \"word_idx\": \"1\", \"dep_parent\": \"4\"}, \"children\": []}, {\"attrib\": {\"word\": \"BMPR-II\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"bmpr-ii\", \"word_idx\": \"2\", \"dep_parent\": \"4\"}, \"children\": []}]}, {\"attrib\": {\"word\": \"is\", \"dep_label\": \"auxpass\", \"pos\": \"VBZ\", \"lemma\": \"is\", \"word_idx\": \"4\", \"dep_parent\": \"7\"}, \"children\": []}, {\"attrib\": {\"word\": \"not\", \"dep_label\": \"neg\", \"pos\": \"RB\", \"lemma\": \"not\", \"word_idx\": \"5\", \"dep_parent\": \"7\"}, \"children\": []}, {\"attrib\": {\"word\": \"signaling\", \"dep_label\": \"nmod\", \"pos\": \"NNP\", \"lemma\": \"signal\", \"word_idx\": \"9\", \"dep_parent\": \"7\"}, \"children\": [{\"attrib\": {\"word\": \"in\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"in\", \"word_idx\": \"7\", \"dep_parent\": \"10\"}, \"children\": []}, {\"attrib\": {\"word\": \"BMP\", \"dep_label\": \"compound\", \"pos\": \"NNP\", \"lemma\": \"bmp\", \"word_idx\": \"8\", \"dep_parent\": \"10\"}, \"children\": []}, {\"attrib\": {\"word\": \"proteins\", \"dep_label\": \"nmod\", \"pos\": \"NNS\", \"lemma\": \"protein\", \"word_idx\": \"12\", \"dep_parent\": \"10\"}, \"children\": [{\"attrib\": {\"word\": \"via\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"via\", \"word_idx\": \"10\", \"dep_parent\": \"13\"}, \"children\": []}, {\"attrib\": {\"word\": \"Smad\", \"dep_label\": \"compound\", \"pos\": \"NNP\", \"lemma\": \"smad\", \"word_idx\": \"11\", \"dep_parent\": \"13\"}, \"children\": []}]}]}]}, {\"attrib\": {\"word\": \"mutations\", \"dep_label\": \"nsubj\", \"pos\": \"NNS\", \"lemma\": \"mutat\", \"word_idx\": \"13\", \"dep_parent\": \"19\"}, \"children\": [{\"attrib\": {\"word\": \"truncating\", \"dep_label\": \"acl\", \"pos\": \"VBG\", \"lemma\": \"truncat\", \"word_idx\": \"14\", \"dep_parent\": \"14\"}, \"children\": [{\"attrib\": {\"word\": \"domain\", \"dep_label\": \"dobj\", \"pos\": \"NN\", \"lemma\": \"domain\", \"word_idx\": \"16\", \"dep_parent\": \"15\"}, \"children\": [{\"attrib\": {\"word\": \"this\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"thi\", \"word_idx\": \"15\", \"dep_parent\": \"17\"}, \"children\": []}]}]}]}, {\"attrib\": {\"word\": \"are\", \"dep_label\": \"cop\", \"pos\": \"VBP\", \"lemma\": \"are\", \"word_idx\": \"17\", \"dep_parent\": \"19\"}, \"children\": []}, {\"attrib\": {\"word\": \"patients\", \"dep_label\": \"nmod\", \"pos\": \"NNS\", \"lemma\": \"patient\", \"word_idx\": \"20\", \"dep_parent\": \"19\"}, \"children\": [{\"attrib\": {\"word\": \"in\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"in\", \"word_idx\": \"19\", \"dep_parent\": \"21\"}, \"children\": []}, {\"attrib\": {\"word\": \"hypertension\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"hypertens\", \"word_idx\": \"24\", \"dep_parent\": \"21\"}, \"children\": [{\"attrib\": {\"word\": \"with\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"with\", \"word_idx\": \"21\", \"dep_parent\": \"25\"}, \"children\": []}, {\"attrib\": {\"word\": \"primary\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"primari\", \"word_idx\": \"22\", \"dep_parent\": \"25\"}, \"children\": []}, {\"attrib\": {\"word\": \"pulmonary\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"pulmonari\", \"word_idx\": \"23\", \"dep_parent\": \"25\"}, \"children\": []}, {\"attrib\": {\"word\": \"PPH\", \"dep_label\": \"appos\", \"pos\": \"NNP\", \"lemma\": \"pph\", \"word_idx\": \"25\", \"dep_parent\": \"25\"}, \"children\": []}]}]}]};\n",
       "var highlightIdxs = [[2], [23, 24]];\n",
       "\n",
       "// Highlight words / nodes\n",
       "var COLORS = [\"#ff5c33\", \"#ffcc00\", \"#33cc33\", \"#3399ff\"];\n",
       "function highlightWords() {\n",
       "  for (var i=0; i < highlightIdxs.length; i++) {\n",
       "    var c = COLORS[i];\n",
       "    var idxs = highlightIdxs[i];\n",
       "    for (var j=0; j < idxs.length; j++) {\n",
       "      d3.selectAll(\".word-\"+chartId+\"-\"+idxs[j]).style(\"stroke\", c).style(\"background\", c);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "// Constants\n",
       "var margin = {top: 20, right: 20, bottom: 20, left: 20},\n",
       "width = 800 - margin.left - margin.right,\n",
       "height = 350 - margin.top - margin.bottom,\n",
       "R = 5;\n",
       "\n",
       "// Create the d3 tree object\n",
       "var tree = d3.layout.tree()\n",
       "  .size([width, height]);\n",
       "\n",
       "// Create the svg canvas\n",
       "var svg = d3.select(\"#tree-chart-\" + chartId)\n",
       "  .append(\"svg\")\n",
       "  .attr(\"width\", width + margin.left + margin.right)\n",
       "  .attr(\"height\", height + margin.top + margin.bottom)\n",
       "  .append(\"g\")\n",
       "  .attr(\"transform\", \"translate(\" + margin.left + \",\" + margin.top + \")\");\n",
       "\n",
       "function renderTree() {\n",
       "  var nodes = tree.nodes(root),\n",
       "  edges = tree.links(nodes);\n",
       "\n",
       "  // Place the nodes\n",
       "  var nodeGroups = svg.selectAll(\"g.node\")\n",
       "    .data(nodes)\n",
       "    .enter().append(\"g\")\n",
       "    .attr(\"class\", \"node\")\n",
       "    .attr(\"transform\", function(d) { return \"translate(\" + d.x + \",\" + d.y + \")\"; });\n",
       "       \n",
       "  // Append circles\n",
       "  nodeGroups.append(\"circle\")\n",
       "    //.on(\"click\", function() {\n",
       "    //  d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"r\", R)\n",
       "    .attr(\"class\", function(d) { return \"word-\"+chartId+\"-\"+d.attrib.word_idx; });\n",
       "     \n",
       "  // Append the actual word\n",
       "  nodeGroups.append(\"text\")\n",
       "    .text(function(d) { return d.attrib.word; })\n",
       "    .attr(\"text-anchor\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? \"start\" : \"middle\"; })\n",
       "    .attr(\"dx\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? R + 3 : 0; })\n",
       "    .attr(\"dy\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? 0 : 3*R + 3; });\n",
       "\n",
       "  // Place the edges\n",
       "  var edgePaths = svg.selectAll(\"path\")\n",
       "    .data(edges)\n",
       "    .enter().append(\"path\")\n",
       "    .attr(\"class\", \"edge\")\n",
       "    .on(\"click\", function() {\n",
       "      d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"d\", d3.svg.diagonal());\n",
       "}\n",
       "\n",
       "renderTree();\n",
       "highlightWords();\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rels.relations[1].render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distant Supervision\n",
    "\n",
    "We can create **_rule functions_** using a variety of helper attributes and tools both from `ddlite` and `treedlib`.  **These functions must return values $\\in\\{-1,0,1\\}$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rule_1(r):\n",
    "    return 1 if 'mutat' in r.lemmas else 0\n",
    "\n",
    "def rule_2(r):\n",
    "    return 1 if re.search(r'{{G}}.*in patients with.*{{P}}', r.tagged_sent) else 0\n",
    "\n",
    "def rule_3(r):\n",
    "    return 1 if len(r.e2_idxs) > 1 else -1\n",
    "\n",
    "rules = [rule_1, rule_2, rule_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [-1.,  1.]])"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rels.apply_rules(rules)\n",
    "rels.rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rels.get_rule_priority_vote_accuracy([1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "Feature extraction is push-button, although custom treedlib feature sets can be passed in as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<95x2 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 187 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rels.extract_features()\n",
    "rels.F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning\n",
    "\n",
    "Here we use a very simple method & implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning epoch = 0\n",
      "Learning epoch = 100\n",
      "Learning epoch = 200\n",
      "Learning epoch = 300\n",
      "Learning epoch = 400\n",
      "Learning epoch = 500\n",
      "Learning epoch = 600\n",
      "Learning epoch = 700\n",
      "Learning epoch = 800\n",
      "Learning epoch = 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ddlite.py:206: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "rels.learn_feats_and_weights(sample=True, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
